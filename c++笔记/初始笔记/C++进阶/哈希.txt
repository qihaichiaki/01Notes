哈希数据结构：unordered_map unorder_set	关联式容器
哈希是一种思想：哈希表是一种数据结构
java就是如下取名的：
	hash_map/set
	tree_map/set

C++下为了向前兼容：unordered--无序的map、set  -- 功能和map和set基本一致。
	哈希这个系列--只提供了单向迭代器。
	（对比map、set的区别）1.map和set遍历是有序的，哈希实现的是无序的。
			2.map和set功能上是双向迭代器，哈希实现的是单向迭代器。

那么基于使用初步相比而言，map和set更强大，为什么需要提供unorder系列呢？
	原因就是在大量的查找下，unordered效率更加强大。
	查找 --  非常快~
	大量数据时，增删查改的效率更加优秀，尤其是查找。



哈希底层实现：哈希表
之前建立了一种二叉搜索树的关系。
现在是哈希--(散列) -- 值和存储位置建立映射的关联关系。这样，查找就是绝对的O1
	类似以前的计数。
		但是它们都有缺点，就是比如给一组整数，如果大小差异过大该如何建立映射关系呢？
			特点：分布不均 -- 1 7 90 1000000 
		那么现在不以范围开空间，以个数开空间。--现在如何做映射？
			方法：除留余数法。
		比如开10个空间：1 = 1%10  7 = 7%10 0 = 90%10 0 = 1000000 % 10
			可以看到还是存在问题，因为这样可能不同的值映射相同的位置。 -- 哈希冲突/哈希碰撞
			解决手段：
				1、闭散列--开放定址法
				找后面的空闲位置：
					a、线性探测
						先看当前位置有没有。没有就直接插入，有就一直往后走，找到一个空闲的位置即可。一直找到null结束。但是如果在这样找中间删除了一个值，那么此时就找不到了列~~~ 此时引入一个标志位即可。
						扩容问题如何解决？引入一个负载因子。负载因子=插入元素个数 / 散列表的长度---负载因子越大，冲突概率越大，越小冲突概率越小。
						扩容满足一个基准：基准值越大，冲突越大，效率越低。但是空间利用率高。
							基准值越小，冲突小，效率高，空间利用率低。
							在开放定址法一般控制到0.7
						
					问题：相互影响，你占我的位置，我占其他人的位置。-冲突越多，效率就越低下。
					b、二次探测

				2、开散列--拉链法/哈希桶
			





1-a	a、线性探测
	// 标记位
	enum State
	{
	EMPTY;
	EXIST;
	DELETE;
	};

	HashData
	{
		pair
		State 
	}

	template class K V
	class HashTable
	{
	public:
		bool insert(const pair&)
		{
			if ( _table.size() == 0 || _size * 1.0/ _table.size() >= 0.7) // 扩容
			{
				// 此时不能相以前那样直接扩容 -- 代价很大，比vector的代价还大。需要进行重新映射
				size_t newsize = size() == 0? 10 : size() * 2;
				vector<> newTables;
				newTables.resize(newsioze);
				// 旧表映射到新表
				for ()
				{//线性探测}
				_tabe.swap(newTables);// 交换

				// 上面代价大：
				size_t newsize = size() == 0? 10 : size() * 2;
				HshTable newTables;
				newTables.resize(newsioze);
				for{// 这里存在，就利用HshTable 复用下面的代码即可}
			}

			hashi = kv.frist % _table.size();  // capacity会访问越界 --[i]的时候    负数没有问题，负数也能存入这个表内。
			i = 0; 
			//线性探测：
			while (_table[hashi].State == EXIST)  // 存在进行线性探测
			{
				hashi++;
				hashi %= _table.size();  // 要回起点的位置，不可越界，找到那个位置
			}
			_tabe[hashi]._kv = kv;
			.state = EXIST
			++_size;

			return true;
		}
	erase
	Find
	private:
		vector<HashData> _table;
		size_t _size;  // 存储多少个有效数据。	
	};
	查找时遇到空停，遇到删除不停。

但是上面存在问题，整型可以取模，但是其他类型就不能取模了。比如string ---	利用仿函数再次映射一个值。
	--仿函数的作用再次体现！伟哉~

template<class K>
struct HashFunc
{
	operator()	return (size_t)size;  // 支持默认可以转的 指针 浮点数 ....
}

//特例比如string可以手动去写
struct HashFuncString
operator()
	可以将ASCII码值加起来~ 只取首字母，冲突太多了
	但是这个也存在一个问题~ 比如 abc、cba、bca等都是一样的哦~
	可以下一次每次乘一个值--字符串哈希算法	BKDR	131


上面加上再添加一个模板参数 Hash

搜索二叉树存K 只需要支持比较大小即可。 -- 
哈希表需要取模，key需要支持取模，不支持取模就需要传入仿函数。
string作为一个常见类型就进行了模板特化。
	

线性探测缺点： 1 11 21 31 2 ... 你会发现，第1个之后全都是冲突的。--会导致互相占用，冲突一片
+i  -hash + i       (i >= 0)

1-b、二次探测：	没有从本质上解决问题  -- 占用式 - 
hash + i^2 (i >= 0)  -- 此时稍微分散了一些去走	
	-闭散列不好，去占别人的位置。

2、开散列--拉链法/哈希桶
	冲突的数据想办法挂起来。
	0  1 2 3 4 5 6 7 8 9 10
	----------------
	    1       4
	    21     14
	    11
 	    31

解决了：不会互相影响 -- 冲突问题得到解决
HashBucket  -- 
KV
最坏情况 -- 都是冲突的，ON  -- 特例：哈希桶看平均 - O1
	增加负载因子 --- 

大于8 -- JDK -- 挂红黑树！！
指针数组
	扩容同样靠负载因子：
Node：pair  Node* next

HashTable：vector<Node*>  size (有效数据)


bool insert(pair)
头插和尾插其实都无所谓 -- 并且这里如果有序的话，对效率没有什么影响，无法二分查找。真正控制哈希桶的效率的是桶的长度。，
	--这里考虑头插
	首先先fine -- 去重

	扩容-如果大小为素数 效率会得到一定的提升。	给定素数数组

Node* Find(K)

一般情况下，哈希桶的负载因子到1就扩容
但是这里扩容可就不能随便扩了，并且不能使用上面的那个方法，也就是复用insert


需要析构函数：
	需要释放桶~


bool erase()
	


哈希的弱势在于扩容需要重新计算位置，并且要挪动桶里面的结点。
当然reserve、rehash -- （库里面）可以提高效率，因为可以提前开空间，就会减少消耗。
平时插入很快 -- 存在一次很慢 -- 就是在扩容。
但是前提是必须知道数据总数。






底层封装unordered_map unorder_set

UnorderedMap.h





	Set.h
namespace bit
{
	template<class K>
}

第二个模板参数决定存什么


套迭代器：	iterator

	哈希桶的迭代器如何去套呢？

	两个指针--一个哈希表的指针，一个结点的指针。
	需要对类进行声明就要1前置声明


比较的仿函数 -- 


一个类型key去做set和unordered_set的模板参数有没有什么要求？
set要求的支持小于比较或者提供比较的仿函数，unordered_set需求的是key类型对象可以转换整形取模或者提供转成整形的仿函数，key类型对象可以支持等于比较， 或者提供等于比较的仿函数。
--Less 小于 想要支持大于只需要换一下参数顺序即可



利用哈希实现了哈希表这个数据结构 -
哈希是一种思想	
关于哈希函数：
	1.直接定址法 - 不存在哈希冲突 （数据集中）
	2.除留余数法 - 存在哈希冲突，重点解决哈希冲突

-----------------------------------------------------------------------
1.面试题：
给40亿个无重复的无符号数，没排过序。给一个符号整数，如何快速查找其是否在这40亿个数中？【腾讯】
	40亿个无符号数占用多少空间？		1G = 1024MB 1024MB = 1024*1024KB ....
					1G = 1024*1024*1024Byte  -- 2^30 -- 10亿左右Byte
	4Byte 	大概16G
	分析：
		1.搜索树和哈希表均不行 -- 存储的时候会出现问题 内存不足
		2.排序+二分查找 - 外排序 数据太大，只能放在磁盘文件上，不好支持二分查找 数据在磁盘，速度太慢了
		3.位图 - 0  1 表示其值在不在   利用直接定址法  -- 一个比特位映射标记值 1在，0不在
		开数组：0 ~ 2^32 - 1 开的是范围 此时所占的空间 - 512MB （4G / 8）
			此时空间足够，效率非常高
位图应用
-------
BitSet.h
class bit_set
{
};

不支持直接按照位开空间，所以用char来开空间
// 利用非类型的模板参数
template<size_t N>
public:
	_bits.resize(N / 8 + 1, 0);  // N是位的个数 N / 8 是表示char的个数
private:
vector<char> _bits;


char
[      ][     ][     ][      ]
set(size_t x)   搞成1
先算第几个char上 然后第几个位上
i = x / 8;
j = x % 8;
_bits[i] |= (1 << j);       左移动是向高位移动


reset(size_t x)  搞成0
i = x / 8
j = x % 8 
_bits[i] &= (~(1 << j));

bool test(size_t x) （x在不在)
i = x / 8
j = x % 8
return _bits[i] & (1 << j);

解决上述问题：
注意，开的是范围：
	bit_set<-1> bs1;  // bit_set<0xffffffff>bs2;



应用：
	1.100亿个整数（肯定存在重复的），设计算法找到只出现1次的整数
	 -- key - val模型  	这里需要三种状态 - 0次  1 次 2次及其以上
	可以设计两个位的位图 00 01 10
		此时开全范围的内存就需要-1G
	可以改 -- 但是可以复用

改+复用：排序 + 去重
template<size_t N>
class twobitset
{
	set()
	{
		// 00 - 01   01 - 10 10 - 10	
		test
	}
	// reset 不存在其概念了
private:
	bitset<N> _bs1;
	bitset<N> _bs2;
};

	2.给两个文件，分别有100个亿个整数，只有1G内存 找到两个文件交集？
		找交集 -- 需要先去重
	先对两个文件进行映射 - 然后在依次遍历  -- 两个都在  ，遍历一下就可以咯- 也可以使用数组来&一下。

缺点 -- 只能处理整数

特点：1.快、节省空间 2.只能映射处理整型，比较局限 3.使用直接定址法，不存在哈希冲突

----------------------
布隆过滤器
--对于海量数据 
	那么现在来了一堆字符串，现在该如何去处理呢？ -- 在不在 key模型
	 -- 字符串哈希算法转成整形去映射一个位置进行标记
	但是基本算法避免不了哈希冲突，在是存在误判的，不在是准确的**（全都是映射完之后的）
优化思路：不可能完全去掉误判，但是可以朝向概率降低的方向去优化
	每个值多映射几个位 -- 理论而言：一个值映射的位越多，误判的概率降低。但是也不能映射太多，映射越多，空间的消耗就越多了。

场景1
	在 （去数据库查一遍）布隆过滤器 不在（直接返回不在）
	数据库


场景2
	注册界面，快速输入提示：
	昵称存在布隆过滤器  -- 在（可以存在误判） 不在继续
	（这样就不用去存储数据的数据库中去找了，速度飞快）
提高查找效率，同时也允许误判的场景；



C++STL没有布隆过滤器
--------------------------------------
BloomFilter.h

template<size_t N, class K, class Hash1, class Hash2, class Hash3>  // N表示要映射N个值  Hash - 仿函数，用来转自定义类型 -- 便于映射
class BloomFilter
{
public:
	void Set(const K& key)
	{
		size_t hash1 = Hash1()(key) % (_ratio * N);  // 注意取模
		_bits.set(hash1);	
		// .......
	}

	bool Test(const K& key)
	{
		size_t hash1 = Hash1()(key) % (_ratio * N);  // 注意取模
		if (!_bits.test(hash1)) return false;  // 不在一定是准确的
		// hash2 hash3 ...

		return true;  // 在存在误判		
	}
private:
	const static size_t _ratio = 5;
	bitset<_ratio* N> _bits;
};


如何确定位图的长度呢？使用布隆过滤器需要的长度和位图的长度想要维持较低的误判率，需要使用公式。
k = m / n * 0.7
k哈希函数个数  m为布隆过滤器长度 n插入数据长度
		k = 3-- 


实现一个复杂程序 -- 求其误判率
误判率和_ratio成反比  或者和哈希函数相关



布隆过滤器：
分别有100亿个query，只有1G内存，如何找文件交集？
比如：网络请求 - sql语法 - 字符串
精确算法：	近似算法：直接放进布隆过滤器

扩展布隆过滤器删除功能：
	能否支持呢？
	->一般不支持删除的，支持的话就会影响其他的值。
	强行支持呢？
	-> 修改 -- 加入引用计数 - 就可以支持删除。但是为了支持删除，空间消耗更多，优势削弱了。

------------------------------------------------
上述的精确交集如何去做？ -- 海量数据处理
--哈希切割
	1.假设每个query 30byte， 100亿个query需要多少空间？ -- 大概需要空间：300G
	1G = 1024*1024*1024byte 10亿字节
	2.假设两个文件叫A和B
	依次读取文件A中的query，i = Hash(query) % 1000;
	这个query就进入编号为Ai小文件
	A：A0 A1 ....... A999

	B同理：i = Hash(query) % 1000
	B：B0 ...... B999

	放到内存的两个set中Ai Bi
	相同的query，一定进入编号相同的小文件里。
	如果分出了大文件，那么就继续切。



	文件太大，不可放入内存  -- 平均切成小文件的话效率太低，利用哈希切割，让相同类似的进入同一个文件，效率提升。  
	
哈希的其他应用：服务器存储数据，查找数据







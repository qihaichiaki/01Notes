---------------------------------------------------------
1.线程概念
	什么叫做线程？
		线程在进程内部执行，是操作系统调度的基本单位。
	补充小知识：
		对于进程-先描述在组织。
			内核数据结构：进程PCB、上下文、进程的页表、进程通信、信号、打开的文件、进程访问其他相关资源。进程代码和数据（通过页表映射 - 用户级页表（每个进程都有一份）、内核页表(只有一份)）。

	task_struct->       mm_struct(进程地址空间)-虚拟地址		内存
			内核区
			命令行参数和环境变量
			栈区
			共享区
			堆区
			全局数据区（已初始化、未）	       （用户级）页表
			代码区			         （进行映射）
		
			像栈区和代码区是被整体使用的。但是堆区实际上是被零散化的。（new malloc ... 申请的空间比较分散）
			malloc -> brk(系统调用) 
			(只告诉其要多少空间，但是没有告诉堆区什么时候结束)
			struct vm_area_struct  -->每次申请一份堆空间就是由此结构体管理。
				vm_start、vm_end	无符号长整数
				*vm_next; *pre;  双链表的结构（在将每一份结构体的对象用链表链接起来）
			整个链表都是在堆区的范围内的。每个结点就是申请的一份堆内存。new malloc得到的就是一份起始地址。
			OS是可以做到让进程进行资源的细粒度划分的。
			
		
		虚拟地址转化为物理地址：
		进程地址空间		用户级页表		物理内存		磁盘
		虚拟地址			+MMU					exe->就是一个
					（大部分集成在CPU中）			文件我们的可执
										行程序本来就是											按照地址空间进											行编译的。
										可执行程序也按								照区域被划分为了以4kb为单位(页帧)
			实际上物理内存也早被划分为4kb（页框）为单位 一块一块的。（操作系统io也是4kb来的）
			OS要不要管理100W+ 4kb呢？4GB
				-必须要管理 -先描述在组织。
				对4kb管理 -struct page  -> 一定会特别小
					-标记位-flags......  
				struct page mem[100W+] ->数组，每次找到数组下标进行访问。
			io的基本单位是4kb 

			缺页中断：页表的右端寻址的时候，内存区不在内存中，去申请页框，在去磁盘找到对应页帧地址，加载带内存，填入物理内存。-> 对用户透明。
			操作系统和编译器均为4kb进行划分的，这样io的基本单位就是4kb。

		如何让虚拟地址映射到物理内存的呢？	
			假设：
				虚拟地址是2^32次方个地址->
				页表中：
					key value 4byte 标记位1byte   一个条目就是9字节（左侧虚拟，右侧物理）
					一共有2^32次方 个条目。（4Gb个映射关系）
					4GB*9？？？？页表会这么大么。

			实际上，出来的一个虚拟地址4byte 32位
			不是被整体使用的。
			0000 0000 00   00 0000 0000    0000 0000 0000
			10	         10                       12
			页表是有多个结构的。
			一级页表（只拿前10位 key-value（二级页表地址））
			二级页表（中10位 key -value（物理内存中某个页框的起始地址））page start addr + 页内偏移（后12位 2^12=4kb）-虚拟地址到特定页
			前20个比特位就可以找到物理内存中特定的页位置。
			最多20M的空间



	如何理解线程？
		task_struct 	mm_struct                页表                 内存
		task_struct	
		task_struct	
		task_struct	
		task_struct	

		通过一定的技术手段，将当前进程的“资源”，以一定的方式划分给不同的task_struct PCB
		-区别：不会申请进程地址空间、页表
		此时这里的每一个task_struct 都可以叫做一个线程。
		所以线程在进程内部执行，是OS进程调度的基本概念。
			-线程在进程的地址空间内运行
			-CPU不关心执行流是进程还是线程，只关心PCB。
		-Linux特有的方案。Linux没有给线程设专门的数据结构。
	
	那么什么叫进程？
		1.从资源角度：
		进程就是：内核数据结构+该进程所对应的代码和数据		-> 用户视角
			（可以存在多个PCB）
		内核视角：
			承担分配系统资源的基本实体。（创建其的第一个PCB -> 向操作系统要资源=进程的身份，线程想要资源就会向此进程要）
		2.如何理解曾经所写的所有代码？
			以前所写的，就是只存在一个PCB ，内部只存在一个执行流的进程。
			现在多线程就是：内部具有多个执行流的进程。
			一大批的执行流（最少一个）+数据代码  
				一个PCB相当于一个进程中的一个执行流。
			
			在Linux视角，task_struct 进程内部的一个执行流。

		3.CPU视角：CPU其实不怎么关心当前是进程还是线程这样的概念，只认task_struct。CPU调度的基本单位“线程”。
	
	在CPU的角度：
	在Linux下，一个PCB <= 其他操作系统PCB的，Linux下的进程：轻量级进程。（拿到的可能是独立运行的PCB，也可能是多线程的进程中的一个执行流）
	


	Linux没有真正意义上的线程结构（没有为其专门设计数据结构），Linux是用进程PCB模拟的线程。
	Linux并不能直接给我们提供线程相关的接口，只能提供轻量级进程的接口。-> 在用户层实现了一套用户层多线程方案，以库的方式提供给用户进行使用。pthread -- 线程库   原生线程库	用户级线程

---------------------------------------------------------
	1.如何验证上述说法？
		创建线程		
		int pthread_create(线程id, attr 属性, 函数指针(入口函数(void*) *()(void *)), void* arg(传递给函数指针的参数));
		成功 0 否则返回错误码
		第三方库 - 不属于C/C++  编译选项：-lpthread 链接库

		#include<iostream>
		#include <pthread.h>
		
		void *threadRun(void *args)
		{
			const string name = (char*)args;
			while (1)
			{
				cout << name << " pid" << getpid() << endl; // 验证pid 查看线程是否在同一个进程				sleep(1);
			}
		}
		
		int main()
		{
			//pthread_t tid;  // 无符号长整数
			pthread_t tid[5];
			char name[64];
			for (5)  创建5个线程
			{
				snprintf(name, sizoef name, "%s-%d", "thread", i);
				pthread_create(tid + i, nullptr, threadRun, (void*)name);
				sleep(1);  // 缓解传参的bug
			}


			// 主线程和新线程
			while (true)
			{
				cout << "main thread pid" << getpid() << endl;
				sleep(3);
			}
		}

		ps -axj 只能查看一个进程。
		ps -aL（L查看量级的进程）
			LWP - 轻量级进程对应的pid pid和LWP一样的，就是主线程。
		
	2.线程如何看待进程内部的资源？
		线程的资源大多数都是共享的：
			文件描述符
			每种信号的处理方式
			当前工作目录
			用户id和组id
			进程地址空间
				代码区是共享的。
				全局变量
				堆区-也是共享的
				共享区 -c c++库
				栈区 -一般认为是私有的

		线程私有：
			id
			*一组寄存器 - 线程自己的上下文   
			*栈（独占结果）
			errno
			信号屏蔽字
			调度优先级


	3.进程和线程：调度层面：上下文
		为什么线程切换的成本更低？
			地址空间不需要切换，页表不需要切换（不切换几个寄存器内存地址的事情）
			核心原因：CPU内部存在缓存的。硬件级别的L1 ~L3 cache 代码数据缓存，对内存的代码和数据根据局部性原理（一条指令的附近的代码大概率被使用）预读到CPU内部。如果是进程切换，进程具有独立性，缓存cache就会立即失效，新进程过来只能重新缓存。


	线程越多越好么？-有可能变成线程切换的负担，而不是任务了
		计算密集型应用，多处理器系统上运行，计算分解到多个线程实现
		io密集型应用，为了提高性能，io操作重叠。线程可以同时等待不同的io操作。
			一般线程数 = cpu的核心数
	
	缺点：
		性能损失（线程多少 - 用户处理失误）
		健壮性降低
		缺乏访问控制
		编程难度提高
	合理的使用线程：提高CPU效率、io密集型效率
			
------------------------------------------
2.线程控制
	线程异常：任何一个线程一旦崩溃，整个进程均会跟着崩溃
	
	clone-> 创建一个轻量级进程 - fork底层调用
	vfork - 创建子进程--和父进程共享地址空间
	
	man pthread_create *线程id 线程属性 线程回调函数void* (*) (void*) 线程回调函数中参数
		传参：
		返回值：(void*)数据; nullptr   返回值是返回给谁呢？一般是给主线程。main如何获取到呢？-线程等待

		验证线程创建
		验证新线程除零错误，查看是否将整个进程异常退出。8号信号
	简单结论：1.主线程和新线程创建出来谁先运行也不确定，由机器的调度器决定。2.线程一旦异常，都可能导致整个进程退出。


	线程在创建和执行的时候，线程是需要等待的。（典）如果主线程不等待会引起类似于进程的僵尸问题，进而导致内存泄漏。
	线程等待
	man pthread_join(id， void **retal)  返回成功 0 ，否则为错误码。 默认阻塞等待新线程。
	// 线程参数和返回
	void *ret = nullptr; 指针变量    （指针其实和指针是不样的 - 指针就是保存地址的，-> 字面常量    指针变量是具体一个变量 -存放对应数据）(void*)10 - > 指针数据
	返回不仅仅整数就可以了，而是可以返回堆空间。
	线程等待不需要关心什么退出异常或者信号-线程一崩，整个进程就没有了。

	
	终止线程：return、exit
	在多线程场景中不要调用exit，exit是终止进程的！
	pTheard_exit(void * );  // 让线程退出的库方法；
	

	线程取消：
	pthread_cancel(id);   
	join退出是-1  
		1.线程被取消，join的时候，退出码是-1    PTHREAD_CANCELD;
	使用此函数的前提条件：存在且运行起来了，并且跑了起来。
		2. 新线程能够取消主线程么 --  可以。但是不可以这么用

	线程id：
		非常大的整数。
		本质是一个地址。
		我们目前用的不是Linux自带的创建线程的接口，我们用的是pthread库的接口。操作系统承担一部分（轻量级进程的调度和管理）库管理一部分（提供属性信息）
		

	task_struct  共享
	PCB线程	------	地址空间		页表 		内存 		磁盘
	线程		共享区	       <-    进行映射			<-	pthread 库
	线程								动态加载入内存
	......
			|
			栈区只存在一个
			如何保证线程每一个是独立的呢？
			用户层提供。

	栈
	主程序栈  -- 主线程就是用的内核栈结构
	mmap区域->		pthread id对应找的就是相关用户属性的集合。
			id->地址 线程id、线程局部存储、线程栈	-- 用户共享区的用户栈结构（不和单线程进程冲突）
	

	man clone -> 回调方法 进程在用户层设置一个栈结构  选项 其他参数  pthread库底层就是调用其clone分配栈空间

	pthread_self() -- 获取当前线程的线程id。
		可以自己取消自己 - 不推荐使用

	

	共享资源：
		查看是否共享全局变量：
		新线程修改全局变量

		__thread 线程私有变量关键字 -修饰全局变量，带来的结果每一个线程各自拥有一个全局变量。（线程的局部存储）
	
	如果线程使用execl-> 带来的结果就是代码和数据全部被替换了，
	一个线程在执行任务，另一个线程突然进行替换- 不会出现问题。只要成功替换了，整个进程就会被替换为其他进程了。主线程外其余线程终止，然后进行进程替换。
	
	


	分离线程：
	当然，和多进程一样，如果主线程不想关心新线程，但是又不想造成内存泄漏问题。注意join不可非阻塞。如果不关心，那么join就是一个负担。
	分离线程，主线程不需要join，新线程结束库会自动去回收。
	// 一般是线程自己分离自己
	pthread_detach(pthead_self());  // 先让此线程处于分离状态
	当然，如果分离后偏要等的话，返回错误码strerror(错误码)；cerrno cstring - 非法的参数
	

	问题：
	1.新线程未回收查无状态，查看不了
	2.线程分离。如果主线程先退出怎么办--主线程退出进程也就会退出，其余线程也都会跟着退出。多进程还是多线程的场景下（一般都是让父进程或者主线程最后退出）注意是否等待什么的都是和环境和场景相关。
	如果线程分离，如果他异常了，那么会影响主线程吗？同样会。（同样的是属于同一个进程）


// 当前我们所使用的是原生线程库
// C++是提供了线程方法。但是实际上C++库引用了原生线程库  ----
	
	
	

---------------------------------------------------------
3.线程互斥：
	线程：cpu调度的基本单位
	进程：资源分配的基本单位
	

	临界资源：多线程执行流共享的资源叫做临界资源
	临界区：每个线程内部，访问临界资源的代码，叫做临界区
	互斥：任何时刻，互斥保证有且只有一个执行流进入临界区，访问临界资源。通常对临界资源起保护作用。
	原子性：不会被任何调度机制打断的操作，该操作只有两态，要么完成，要么，未完成。
	
	// 如果多线程访问同一个全局变量，并对它进行数据计算，那么多线程会互相影响吗。
	此时多线程访问的同一个函数就是可重入函数。
		如果对共享资源不加保护，存在问题。
		每个线程都会访问内存中的共享资源，每次--。要完成--动作，在特定的线程里面读取到cpu寄存器中，然后进行--，最后在写入内存中。因为这样的存在，随时就有可能存在线程切换。（寄存器数据都是当前线程的上下文数据，等下次来就会恢复），那么此时就存在时序问题，不是原子性的操作。
		出现-1的情况同样如此。也是时序问题，sleep 1 （本来读入是1 ）但是等待过程中被其他执行流--了，那么此时将会拿到0，但是已经进入if条件判断了。
		或者并发访问-
		1.判断的本质也是计算的一种。并发进入。
		2.在进行计算的时候，也有可能存在问题。
			tickets--;
			读取数据到cpu内的寄存器。
			CPU内部进行计算。
			将结果写回内存中。
		    在执行上面三步中如果存在时序（线程切换）问题，那么同样的存在问题。

	如何避免上述多线程访问全局变量出现的问题呢？
	// 加锁保护
-互斥锁
	pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);  // 对此锁进行初始化。（第一种就是使用此接口）
	pthread_mutex_t mtx;  // pthread_mutex_t就是原生线程库提供的一个数据类型
	1.锁是全局的 静态分配
	如果是全局或者静态的2 -> 可以直接初始化：PTHREAD_MUTEX_INI.....
	// 对临界资源进行加锁保护 -- 对临界区进行加锁保护
	pthread_mutex_lock(pthread_mutex_t* );  对需要并行的地方进行上锁
	unlock 解锁
	while(true)
	{
		pthread_mutex_lock(&mtx);  // 任何一个时刻，只能让一个线程获取这个锁，其余线程到这里，只能阻塞进行等待，直到此线程进行开锁。
		//......    只能串行的进行执行。 --- 临界区。
		//解锁
		pthread_mutex_unlock(&mtx);  // 解锁  注意必须选对区域进行解锁-如果不解锁其余线程均无法运行。
	}
	vim - /查找 对应的字符
	
	可以看到时间明显缩短，但是由于休眠时间一致-或者cpu调度的原因，可能只看着一个线程在跑。
		抢完票其实还需要后序的动作。usleep(rand()%2000);  模拟后序的动作
	
	注意：加锁的时候，一定保证加锁的力度越小越好。（别把无关紧要的代码放入临界区）
	
	2如果不是全局的。 动态分配
class TreadData
{
public:
	string tname;
	pthread_mutex_t *pmtx;
}

	pthread_mutex_t mtx;
	pthread_mutex_init(&mtx, nullptr);// 初始化锁	成功返回0，失败返回错误码
	pthread_mutex_destroy(&mtx);// 释放锁
	
	pthread_t t[5];
	for(int i = 0; i <= 5; ++i)
	{
		// 让局部定义的锁如何向线程传递呢？
		TreadData *td = new TreadData("", &mtx);  // 注意每个线程最后需要释放一下。-智能指针的重要性！！！
		pthread_create(t + i, nullptr, 回调函数, (void*)td); -> 传入自定义类型、对象。
	}


	time 秒级别 -获取当前的时间戳 time_t long int
	gettimeofday();  // 微秒级别的接口
	
加锁就是串行执行了么？加锁了之后，线程在临界区中是否会切换，会存在问题么？原子性的体现？
	加锁后，线程同样的会进行切换，但是完全没有影响：
		第一次理解：执行到此区域一定是上了锁了的，并没有解锁。所以即便是切换，其余相关线程都需要申请锁，无法申请成功，自然就无法干扰临界资源，即无法执行临界区代码。保证了临界区中数据一致性。
		（锁的原理）第二次理解：一旦切换了，寄存器中唯一的锁（1）也被此线程保留走了，其余线程不可申请锁。		
	我是一个线程，不申请锁，就是单纯的访问临界资源---错误的编码方式 -类比于现实生活中的违反规则。
	
	原子性的理解：在没有持有锁的线程看来，对其有意义的情况只有两种：1.线程1没有持有锁（什么都不做） 2.线程1释放了锁（做完了）。因为此时才可以申请锁。
	加锁就是串行执行么？是的，但是前提是执行临界区代码，一定是串行的。
	
要访问临界资源，每一个线程必须先申请锁，每一个线程都必须先看到同一把锁并且去访问它，锁本身是不是就是一种共享资源？谁来保证锁的安全呢？
	所以为了保证锁的安全，申请和释放锁必须是原子的。如何保证呢？锁是如何实现的？

	swap或exchange指令：以一条汇编的方式，将内存和cpu内寄存区数据进行交换。
	如果我们在汇编的角度，只有一条汇编语句，我们就认为该汇编语句的执行时原子的。
	lock：加锁
		movb $0 %al	0放入寄存器中：0属于线程的上下文
		xchgb %al, mutex    把寄存器的值和锁的值进行交换  -真正的申请锁  交换-数字1永远只有一个。（对应线程没有申请锁内存中1和寄存器 的0进行交换）锁代表1 - 锁被其余线程占用表示0  --内存mutex中
		if (al寄存器的内存 > 0) return 0;
		else 挂起等待
		goto lock;
		
	交换的现象：内存<->%al做交换
	交换的本质：共享<->私有 // 在执行流，如何看待cpu上面的寄存器的？当前执行流的上下文。寄存器们，空间是被所有的空间共享的，但是执行器的内容，是被每一个执行流私有的，上下文。（在此执行流使用期间，一定是自己的数据）
	
	注意：交换并非拷贝，那么1永远就只有一份。所以申请锁的部分就是原子的。

	unlock：解锁
	将寄存器中的内容和内存对应mutex 交换即可


	线程a

cpu			内存
%al			mtx
	

	*自己保证锁的安全。

可重入和线程安全
	同一个函数被不同的执行流调用。出问题->不可重入，否则可重入	--描述函数的（函数特点）
	线程安全：对全局或者静态变量进行操作，并且没有锁的保护的情况下，在多线程环境下被称为线程安全问题。  --描述线程的。（多线程上的要求）


	常见的线程不安全：共享变量的函数，状态随着函数调用产生变化， 返回静态变量指针的函数....
	不可重入：malloc、free I/O库函数 标准I/O库都是以不可重入实现的 静态的数据结构

	线程安全的情况：
	不可重入的情况
	可重入的情况
	区别：：如果一个函数是可重入的：那么一定就是线程安全。如果是线程安全的，但是不一定是可重入的。......


---------------------------------------------------------
4.常见锁的概念：
	死锁：
		可能不止用了一把锁
		线程A 申请锁1  申请锁2    线程B 申请锁2 申请锁1
		如果线程A有1现在要2，但是线程B有2现在要1  ，此时造成尴尬的问题---- 
		互相申请对方锁的情况 -- 死锁。
		
		1把锁可能产生死锁吗？？？ -- 可以
			在拥有锁的线程在解锁之前再次申请锁。(此时无法再被唤醒 -- ）
		
		多线程场景中：自身具备锁的情况下申请其余有锁，互相申请导致不会释放永远等待下去的过程。
	
	
		死锁的必要条件：1.互斥条件（一个资源只能被一个执行流使用 - 互斥锁） 2请求与保持条件（一个执行流因请求资源而阻塞时，对已获得资源保持不放） 3不剥夺条件（一个执行流已获得的资源，在未使用完前，不可强行剥夺） 4循环等待条件（若干执行流之间形成一种头尾相连的循环等待资源的关系）
			死锁一旦产生，上述四个条件一定被满足
		
		避免死锁：破坏死锁的的四个必要条件（1能不能不加锁 2trylock()-如果申请成功返回0，申请失败也可以返回，返回错误码--不会阻塞式的等待，连续申请数次不成功，然后释放自己的锁 3强制的抢占他人的锁（优先级越高）4所有线程必须按照一定顺序申请锁，不可交叉申请 ）；加锁顺序一致；避免锁未释放的场景；资源一次性分配。
		避免死锁算法：

-----------------------------------------------------
5.*线程同步
线程同步的概念：
	互斥锁例子（每次票只是一个线程抢到）：1.频繁申请到资源 （别人干什么呢）
	                           （申请资源频繁去申请，）2.太过于浪费我自己和对方的资源了
		上述例子均没有错，但是均不合理。1.自己频繁的占用造成别人饥饿的问题 -- 只有互斥（完全听天命-随机性）2.一定时间释放资源，但是在等待过程中，一直在上锁解锁去等待资源--无用功（在之前的抢票加入一个线程进行放票工作就可以模拟了）

	为了解决上述问题，引入同步：解决访问临界资源的合理性的问题
	线程按照一定的顺序进行临界资源的访问 -- 线程同步 执行过程具备一定的顺序性。
	竞争条件：因为时序问题，导致程序异常。

方案1：条件变量	-- 2
	概念。
	当我们申请临界资源前->先要做临界资源是否存在的检测 -> 要做检测的本质：也是访问临界资源！！-> 结论：对临界资源的检测也一定是在加锁和解锁之间的。
（常规方式要检测条件就绪，注定了必须频繁申请和释放锁）-> 有没有办法让我们的线程检测到资源不就绪的时候：1. 不要让线程频繁自己检测，等待。2.条件就绪的时候通知对应的线程，让他来进行资源申请和访问。-条件变量
	

	共识：申请资源，先做检测。（不光光抢到锁了，资源来不来不确定，需要检查）

	接口：cond
	条件变量 -- 等待和唤醒操作
		条件变量 - pthread_cond_t 
		全局变量 - 设置宏，否则局部使用接口 des....
		pthread_cond_init  
		
		条件等待
		pthread_cond_wait 等待特定的条件变量    参数：条件变量 互斥锁
		pthread_cond_timewait()  设置时间，特定的时间会醒来
		
		条件发送通知
		pthread_cond_broadcast 条件变量  唤醒全部等待线程
		pthread_cond_signal   条件变量 唤醒指定的一个线程

	上述接口，返回：成功0，失败返回错误码。
	// 简单demo进行理解上述接口：
		创建多线程，主线程：指定按照顺序的方式唤醒1234新线程。线程做不同的事情
#define TNUM 4
typedef void (*func_t)(const string name);
class ThreadData
{
public:
	string name;
	func_t func;
};
	
int main()
{
	创建一批线程线程(//1 并且加载入一批函数  // 2利用传入线程的自定义类型进行保存)
	for ()
		create
	
	return 0;
}	

		pthread_mutex_t mtx;  // 互斥锁
		pthread_cond_t cond;  // 条件变量

		// 局部变量进行初始化
		mutex_init(&mtx, nullptr)  // 变量 属性
		cond_init(&cond, nullptr)
		
		// 让所有线程拿到同一把锁。
		// 新线程1 ... ... 
			pthread_cond_wait(条件变量地址, 互斥锁变量地址); //条件变量必须配一把锁  wait代码被执行，当前线程会被立即阻塞。-挂起	进入队列进行等待 -- 条件变量通过系统调用提供    //只是这一行代码不行 -- 这里的位置一定要在加锁和解锁之间进行wait  
	
			pthread_mutex_lock(pmtx);
			if（临界资源是否就绪-- 否：）pthread_cond_wait(条件变量地址, 互斥锁变量地址); 
			// 临界资源进行使用
			unlock(pmtx);

		// 控制新线程顺序：
		while (true)
		{
			pthread_cond_signal(&cond);  // 唤醒指定线程的条件  -- 只关心，确定在等待队列中的一个线程去唤醒	
			//pthread_cond_broadcast(&cond);  // 当前等待队列线程全部被唤醒
			sleep(1);
		}

		destroy(&) // 销毁


	1.条件满足的时候，我们在唤醒指定的线程 -- 我怎么知道条件是否满足呢？
	2.mutex的意义？

生产者消费者模型：
	1.例子说明，生产消费的基本组成概念
		消费者 		超市-交易场所		生产者
			核心价值：提高效率 解耦（生产者和消费者之间）
			本质：就是一个商品的缓冲区
			
			研究模型：1.两种角色：生产者-消费者
				2.一个交易场所
				3.对于消费者和生产者来说，交易场所均为共享的。 -- 三种关系：生产者和生产者（互斥关系（竞争） -- 对于同一类型），消费者和消费者（缺货的时候，针对稀缺物品 -- 互斥关系（竞争）），生产者和消费者（生产中，消费者不可消费 -- （生产前 生产中 生产后  -- 要么生产前、生产后 生产中就需要维护 - 互斥）互斥/（资源条件问题 -- ）同步）
			
			遵守的原则：321原则。

			生产者是知道缓存区的数据的
			消费者同理。

	2.用基本工程师思维，重新理解cp
		生产者和消费者 -- 线程承担。-给线程进行角色化。交易场所-某种数据结构所表示的缓冲区。商品-数据
		生产者生成的商品，就可以告诉消费者可以消费了。消费者消费了就可以告诉生产者可以生成了。--

	.条件满足的时候，我们在唤醒指定的线程 -- 我怎么知道条件是否满足呢？ - 我不知道，但是线程知道。

	问题：
		1如果消费者和生产者只存在一个，那么（同类型）之间就不用维护互斥问题了。
		2数据生产到仓库，在合适的时候被消费者拿走。但是生产消费的过程不仅仅于此。生产者生产的数据是哪里来的？（不清楚，但是花时间）消费者如何使用发送过来的数据呢？（不知道，但是也要花时间）
	


基于BlockingQueue的阻塞队列模拟生产消费模型：
	多线程编程中阻塞队列是一种常见于实现生产者消费者模型的数据结构。
	
	进程间通信的前提：看到同一份资源	本质：生产者消费者模型（管道本身就是一个简单的阻塞队列）

	代码操作
		cond_wait 同样的也是在临界区中！我是持有锁的，如果我去等待的，此时这把锁该怎么办呢？？？第二个参数：pthread_cond_wait  当成功调用wait之后，传入的锁会被自动释放。然后自己挂起。当被唤醒的时候：从哪里挂起就从哪里唤醒，被唤醒的时候我们还是在临界区中被唤醒的，所以锁还是会被加上。
		但是注意，只要是一个函数都有可能调用失败。-如果失败了比如阻塞函数wait -- 除此之外也可能存在伪唤醒的情况。这两种情况都造成了访问临界资源。所以就需要用while进行循环等待判断，避免因为特殊情况造成条件不满足而访问临界资源的情况。  -- 条件变量的使用规范



效率的体现：生产者生产数据需要花时间，消费者消费数据需要花时间。实现两种线程的并发过程。--非临界区的执行并发优化。因为临界区是串行执行的，并不能提高效率。


	demo举例：
		加入自定义任务Task.hpp
		// ......
		


		// 多生产和多消费
		

多生产和多消费的意义在哪里呢：可以让生产行为和消费行为让有多个执行流进行并发的处理。

	锁的设计：lockGuard.hpp
		//让代码变得更加优雅
		{ } -- 一个代码块，在此区域里定义的局部变量出此块均会释放
	
	RAII的加锁方式
	


方案二 - POSIX信号量
	与进程间通信的信号量作用相同，用于同步操作，达到访问共享资源的目的。
	接口：
		semaphore.h
		sem_init(sem_t *sem, int pshared, unsingned int value);
			sem 信号量变量
			pshared:0表示线程间共享，非零为进程间共享
			value:信号量初始值
		sem_destroy

		p sem_wait(sem)  -- 申请
		v sem_post(sem) ++发放


	什么是信号量？
		1.共享资源->任何一个时刻都只有一个执行流在访问-> 临界资源、临界区的概念
			互斥->共享资源是被当做整体使用的。
			如果多个线程访问的是资源的不同区域的话，如果是互斥去访问，结果是对的，但是效率太低了，所以此时可以让多线程并发的去访问。（线程==执行流）  但是：1.你怎么知道一共多少个资源，还剩多少个？（信号量的值）2.你怎么保证这个资源就是给你的呢（程序员编码）？我一定可以具有一个共享资源呢？（信号量本质就是一个计数器，是预定的机制）
		
		2.电影院的例子：
			买票->确定座位
			买票的本质：叫做资源（电影院中的座位）的预定机制。
			信号量本质：是一个计数器，访问临界资源的时候必须先申请信号量资源（sem--）预定资源（p），使用完毕对应的信号量资源（sem++）释放资源（v）。
				
	

	如何理解信号量的使用
		我们申请了一个信号量-> 当前执行流一定具有一个资源可以被其使用->那么是哪一个资源呢？需要程序员结合场景，自定义编码完成。

	

	基于环形队列的生产消费模型:
		中间环节更换为环形结构.
		环形结构利用数组进行实现.(链表也可以)
			逻辑结构是环状的,物理结构是线性的.
			0 1 2 3 ... n - 1  (n)
			index++;
			index %= n; -- 利用模运算来模拟环状结构

			注意:1.判空 2判满   两个下标相等(生产者指针/消费者指针) if(start == end)?不可 a.加计数器 b.专门浪费一个格子 -- 镂空设计

		代码设计:
			读端:消费者 写端:生产者
			环形结构中,为空消费者不可进行,为满生产者不可进行.此时两者是处于同一位置的.如果生产和消费指向了环状结构的同一个位置(为空或者为满):生产者和消费要有互斥和同步问题.(无论消费者还是生产者,只能有一个再跑)但是此事件是小概率事件,大部分都是生产和消费指向的是不同的位置.-->*想让当生产者和消费指向同一个位置,具有互斥同步关系即可.而当不指向同一个位置的时候,让他们并发执行!!	
			期望:
				生产者不可将消费者套圈.-数据覆盖
				消费者不能超过生产者.
				为空:一定要生产者先运行.
				为满:一定要消费者先运行.
				其他情况并发执行
			
			编码:信号量
				生产者:空间资源 ->spaceSem-> N
				消费者:数据资源 ->dataSem->0
				生产:p(spaceSem--)(大于0--,否则会阻塞挂起)->信号量申请成功:特定位置生产->v(dataSem++)注意此时生产者生产完了退出,此时当前信号量不可被释放,因为此资源依旧是被占用的.但是数据资源需要增加.
				消费:p(dataSem--)(大于0--,否则会阻塞挂起)->信号量申请成功,特定位置消费->v(spaceSem++)数据被消费了,此空间释放.
			
			RingQueue 环形队列

			在多线程环境下(多生产者和多消费者) 在上述单线程的条件下,需要互斥保护下标.信号量.保证每次生产者们和消费者们一次只有一个申请信号量并且进行push或者pop 但是注意信号量本身是原子性的,在临界区越少越好,所以可以把信号量放在临界区外.**先申请信号量 后加锁
			(效率体现在资源是否尽快分派给各个线程 - -)  ::: 形象的例子:先上锁->  电影院排队买票入座  先申请信号量->先购票(网上购票),凭票入座
			
	多生产多消费的意义在哪里?
		可以让生产行为和消费行为让有多个执行流进行并发的处理。
		生产的本质:私有的任务->公共空间
		消费的本子:公共空间的任务->私有的
		// 排队吃饭 排队打饭 ->短时间 每个人吃饭--并发,提升效率

	信号量的本质是计数器,计数器是什么?
		先前(阻塞队列)是先申请锁,在进行判断,最后在释放锁 -不清楚临界资源的情况是什么样子- 
		信号量要提前预设资源的情况,而且在pv变化过程中,我们可以在外部就知晓临界资源的情况.减少临界区内部的判断.



-----------------------------
6.线程池	
	池化技术 -资源的预分配机制-
		比如申请空间,如果需要才向系统申请空间,每次系统申请空间会非常麻烦,耗时间,导致整体的效率降低... 所以一般就会预先多申请一部分.提高空间的使用效率 空间换时间的做法。
		类似的,预先创建一批线程,每次需要创建线程执行任务提供其中的一个线程进行执行即可.而不是每次需要创建线程就去系统去创建.更何况线程的创建可不单单是申请空间那么简单.

	ThreadPool:
		编码:
			thread.hpp
			threadPool.hpp
				一批线程 一批任务
				vector<Thread*>  queue<T> 
				void* routine()  -- 线程执行函数
				run线程启动  pushTask派发任务
				show() 
			testMain.cpp
			
		本质就是一个生产消费模型.
		首先pushTask 塞任务 - 生产者     线程池中的线程竞争或者同步的进行执行
			生产者与生产者需要互斥，并且生产者和消费者需要同步（注意生产者没有限制，即随时放任务 -- ） 
		优化方式：-挑战一下-
			queue1 queue2
			queue<T> *p_queue, *c_queue  生产的队列 消费的队列
			p_queue-> queue1  生产一批任务之后，swap(p_queue, c_queue) ,唤醒所有或者一个消费者线程。
			c_queue-> queue2、
			消费者处理完毕的时候，再次进行交换队列。因为我们生产和消费用的是不同的队列，未来我们要进行资源处理的时候，互相影响的就仅仅是指针而已。

		log.hpp 日志头文件 -每次打消息使用此头文件-
			日志是有日志级别的。不同的级别代表不同的响应方式：
		DEBUG	NORMAL       WARNING	 ERROR		FATAL
		0	1   	       2 	     	3		4
		测试	常规               警告   		错误(不影响执行)       致命错误

			完整的日志功能：基本：日志等级 时间   支持用户自定义 日志内容 
			const char* format, ... -> 可变参数  (日志内容也可以包含内) 和printf类似 format是格式
				man va_start->使用可变参数
				va_list-> char*  a
				va_start(a, format);  //  初始化 参数的起始地址设置进来
				int x = va_arg(a, type);  // 没有返回null
				va_end(a);  a = nullptr;
	
				除了上面的，还有下面的可以处理可变参数 但是需要va_list va_start
				man snprintf 
				stdarg.h
				// vsprintf();  打到显示屏内的
				
			时间：man localtime  time_t->时间戳 无符号长整数 time.h long int
				time(时区)-> 获取时间戳   时区默认即可  
				struct tm -- 

				__FILE__ __LINE__	-预处理符号- 日志使用 文件和行数
			
			-D 命令行定义 宏


-------------------------------
线程安全的单例模式
	懒汉模式存在线程安全问题，就是在初次创建的时候，并发造成了创建了两次。
	-将上面的线程池改为单例模式-
	-懒汉模式-

	// 首先内部需要定义一个自身的指针，方便提供给外部。
	static threadpool<T> *thread_ptr;  // 不属于对象，属于类
	// 注意外部置为nullptr
	构造函数设为私有，拷贝、赋值函数删除
	提供静态接口 getThreadPool 第一次（nullptr）进行类里创建 其余只能获取第一次的指针数据。
	
	如果单例本身也在被多线程申请使用呢？？？---多个线程使用的话，那么就设计到线程安全问题了。
		需要加上一把静态锁（注意此时有可能对象没有创建，所以无法使用对象内的锁
		lock
			if ==nullptr
				new
		unlock
		// 注意上述代码还是存在问题，虽然保证了线程安全，但是未来任何一个线程想获取单例，都必须调用此接口-那么都必须先加锁。----本身就应该只是第一次申请 -- 效率低下。
		所以需要在外面再进行一次判断即可，这样在后序并发执行的时候就不用申请锁了。
		if ==nullptr
		lock
			if ==nullptr
		...



STL中的容器不是线程安全的。 -所以之后多线程环境下需要加锁操作-
智能指针的话 - unique_ptr 只在当前代码块范围内生效 -不涉及 shared_ptr 多个对象需要引用计数 -存在线程安全问题。

其他常见的各种锁：
	悲观锁：互斥锁 - 信号量
	乐观锁：我修改数据时，别人不会修改，不上锁。但是更新数据前会判断其他数据在更新前有没有对数据进行修改 版本号 - cas操作	
	CAS操作：-原子操作-
	自旋锁：
		什么叫做自旋？
			悲观锁：新的执行流 阻塞（PCB - 投入到锁的等待队列中）
			
				多线程
				临界区
				多线程
			线程挂起等待资源的策略:临界资源就绪的时间
			线程不断的去检测资源是否就绪 - 轮询检测-自旋
		本质就是通过不断的检测锁的状态，来进行资源书否就绪的方案。
		什么时候使用自旋锁呢？
			资源就绪的时间问题。（时间短选择自旋锁
		时间长短 - 业务逻辑的容忍度

		man pthread_spin_init --pthread
		数据类型 pthread_spinlock_t
		接口：lock unlock

读者写者问题：
	321原则 - 类似生产者与消费者模型
	-黑板报-
		

	写者和写者 互斥
	读者和读者 共享* 
	写者和读者 互斥（防止读者拿到数据不一致） 同步（读者读完，在写 ）

	写者
	交易场所
	读者

	与生产消费的本质区别：消费者会取走数据，读者不会
	
	int reader_count = 0; 读者个数（读者线程
	
	读者：
	lock();
	reader_count++;
	unlock();


	lock();
	reader_count--;
	unlock();

	写者：
	lock();
	if (reader_count > 0) unlock(); return;  // 与读者进行互斥
	// 走到这里，没有读者了
	// 写入
	unlock();

接口：pthread_rwlock_init -- 把mutex换成rwlock即可
区别：
	读者：rdlock  计数器
	写者：wrlock  看是否有读者
	释放：unlock
		
	读者优先，写者优先问题。（生产和消费基本对等的）--应用场景--数据被读取的频率非常高，修改的概率特别低。(博客) 写者出现饥饿问题是正常的。
	默认读者优先 - 同时发生 读者和写者同时访问资源 
	-查票逻辑-可以写一写

	
			
				
	





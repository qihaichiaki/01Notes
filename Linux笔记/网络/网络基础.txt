系统是网络的基础。

-概念-关系-基础1-

域网：
	一开始计算机是独立运行的，如果进行协同操作的话，效率非常低下。
	所以诞生了服务器，几台电脑链接在一起。网络互联
	局域网LAN：计算机数量更多了 局域网之间通过路由器进行连接。
	广域网WAN：远隔千里的计算机连在一起。

		所谓局域网和广域网是一个相对的概念，规模的大小进行区分。
		网络不断壮大，是由通信企业做的。（国内：三大运营商、华为）

网络协议：
	协议是一种约定。
	为什么存在协议？
		两个计算机通信互相发送数据，数据是存在类别的。但是计算机里只存在01，所以需要区分，需要约定协议区分类别以及减少成本（增加有效的动作，减少无效的动作）。
	做好软硬件通信协议：统一起来就是行业标准（硬件标准。
	1.操作系统要进行协议管理 -- 先描述，在组织
	2.协议本质就是软件，软件是可以分层的。
	3.协议在设计的时候，就是层状的划分的。->为什么要划分为层状结构？a场景复杂 b功能解耦 ，便于人们进行各种维护。
	
	通信的复杂，本质是和距离成正相关的。
	复杂体现在哪里？ -- 协议栈要解决的问题？
		通信范畴：1.丢包 2.定位问题 3.解决下一跳主机的问题。（中间路过的主机）
			2传输层   3网络层	4数据链路层  5物理层	A主机-> B主机
			TCP	ip		
		应用范畴：如何处理数据。--- 1应用层
		上面的一整个生态-基于TCP/IP协议- 5层协议 

		lib shell 应用软件		应用层
		system call		|
		操作系统			传输层、网络层***
		驱动			数据链路层
		硬件			物理层
		（重点是上四层-软件级别）
	但是先存在OSI（开放系统互连）七层模型，--草稿、蓝图 后序存在TCP/IP协议
		帮助不同的主机进行数据传输。逻辑上的定义和规范。
		区别：应用层多加了表示层和会话层 （在自己的设计中需要进行表示）
	
	TCP/IP五层模型
		物理层：信息传递的物理介质。光纤、wifi-电磁波 传输速率，距离、抗干扰器。设备：集线器、调制解调器（数字和模拟信号进行转化）。
		数据链路层：设备之间的数据帧传送和识别。局域网-以太网 无限LAN标准 设备：交换机-
		网络层：数据包定位目标主机。地址管理和路由选择。设备：路由器。
	-已经保证能从A->B了-
		传输层：负责两台主机之间的数据传输。-TCP 设备：主机
		应用层：程序交流使用。

网络传输的基本流程：
		两台主机在同一个局域网内是可以通信的（比如投屏）
	逻辑上讲，应用层直接发送给应用层。（同楼层但是不同楼）但是物理上自顶向下，链路层-> 自底向上，应用层。
			主机A      <->     主机B
		封装	       应用层 FTP协议		解包

			       传输层 TCP协议

			       网络层 IP协议

			       链路层 以太网（局域网）

	每层都有自己的协议定制方案，每层协议都要有自己的协议报头。
	从上到下-添加报头。从下到上-去掉报头。报头类似于-发送快递的单（卖家（向下交付-填好单子(给快递看的)） - 买家(收到了快递，不会要快递单)）同层协议收到数据包后，多出的一部分就是报头。层层封装成一个数据帧-添加报头的过程。经过局域网通信后，在向上交付 - 一层层通过报头识别对应部分(除开报头，那么就是有效载荷)向上交给什么协议，向上将有效载荷向上交付。重复上述步骤一直到应用层为之。
	封装的本质：添加报头
	解包：去掉报头&展开分析
	可以想象为栈结构：封装就是不断的压栈，解包就开始不断的弹栈即可。
	同层在逻辑上就是直接通信。
		
	局域网传输-链路层：类似于学生在教室里上课，老师点名学生名字。在局域网内每台主机都接收到了，只有通信的那段拿到数据包解包，其余识别不是自己就直接丢弃。同样的，如果两台主机在同一局域网通信，另一台主机如果干扰，那么就会无法通信-发生碰撞问题-缓解措施：等一会，再进行重发（注意是同一局域网的全部主机都需要遵循）。
	局域网中表示主机的唯一性：MAC地址。-网卡里确定了
	命令：ifconfig  eth0:云服务器的    ether：限制16进制  48位 以太网地址 MAC地址。inet ip地址 -内网ip
		以太（光传播的介质  -实际上并不存在）计算机世界对此进行命名对局域网的链接的协议。




	那么如果不再同一个局域网里：
			主机A      <->     主机B
	       应用层 FTP协议		解包	应用层 FTP协议	

	       传输层 TCP协议			传输层 TCP协议

 	       网络层 IP协议	    <---路由器--->	网络层 IP协议

	       链路层 以太网（局域网）	|X|	链路层 令牌环（局域网）  	因为不再一个局域网，所以需要交给路由器，通过以太网驱动程序去掉以太网协议报头，交给路由器。如果目标ip路由器在同一局域网，那么就向下交付其对应协议的驱动程序进行添加报头，然后就是从下到上开始解包。  --同层协议。此时往上三层的协议一致，只是链接层不一致。
				

	A无法利用MAC地址发送，A向B发送，就利用B的ip地址进行发送。
	MAC地址 - IP地址
		例子：西游记：唐僧-(东土大唐、西天)（问别人的时候，别人可能会告知下一站应该去哪里-现在在A				源IP    目的IP							源mac地址   下一站mac地址  -- 每一台路由器。
，下一站去B）    mac地址会随着当前地址会不断变化。下一站mac地址是受到目的ip地址影响的，决定方向。
	
	在使用TCP/IP协议中，在中间路由即ip以上看的协议是一致的。即报文也都是一样的。
	
		主机A    					主机B
	       应用层 FTP协议					应用层 FTP协议	

	       传输层 TCP协议					传输层 TCP协议

 	       网络层 IP协议	  路由器			路由器	网络层 IP协议

	       链接层            解包       添加---------------  解包        添加  链接层
-------------------------------------------------------------------------------------------------------
	1.保报文是要被封装的，如何解包？			每一个协议都需要考虑的，协议都要解决这两		2.决定我们的有效载荷交付给上一层哪一个协议的问题？             个公共问题
	

	IP地址：IPV4、IPV6  IPV4-32位整数 点分十进制
	


-----------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
应用层：
----------------
协议---------
序列化与反序列化

自己写应用层：

	实现一个网络版计算器
		服务器版  客户端吧需求发送过去，服务器计算后返回结果。
		约定方法1：解析字符串
		约定方法2：定义一个结构体。将结构体对象发送，服务器根据结构体提取数据计算结构，计算后返回一个结构体对象-含有结果和一个code。
			-可以这么干。但是其可扩展性太差了-服务器端一变，客户端使用不了了。 但是注意操作系统可能不同  -- 对于不同平台的数据，存在大小端、内存对齐出现不一致的问题。所以不可直接发结构体，所以一般需要先序列化-转化为字节流（大的字符串） -- > 送给对方，对方读取并且进行解析。解析一变多久变成了反序列化。字节流-> 结构
			
			结构化数据		上层业务
		序列化  -------------   反序列化
		          字节流&&字符串          		网络比较适合传输

	
所谓协议定制：
	字段本身就是协议的一部分。
		新增文件：
		Protocl.hpp 自己定的协议
			定义结构类型
			序列化     -- 转化为字符串
				1.自主实现：
					"x op y"
				----一般使用现成的方案 - 这里只是理解
				
		需要注意，如果读端关闭，那么写端继续或者在写就会出现问题，会发送SIGPIPE - 13信号。
		解决做法：1，服务器上一般捕捉此信号进行忽略。2.查看读取的结果 进行处理，直接不发送即可。一般两个方法都要使用。
		但是，如果正在发的时候，如果关掉的话，就只能进行自定义捕捉忽略了，否则服务器进程就会被干掉。SIG_IGN  一般服务器都要忽略13号信号，防止非法写入的情况。
		约定。
			-看的到的结构和看不到的顺序
	
		// TCP是面向字节流的，
		// recv - read 读取时，你怎么保证缓存区的内容是一个完善的请求呢？  -- 目前不能保证
		// UDP是发一个数据，然后收一个数据。但是TCP就可能发送了多个请求 - 多执行流进行操作

		传输控制协议：TCP、UDP
		client				server
		发送缓冲区（存在接收缓冲区）		接收缓冲区（.....）
		send/write
			:之前认为是发送给网络或者对方主机中 -- 是错误的。所以只是拷贝到了发送缓冲区，接收同样如此。 -- 
		
		1.io接口：本质都是拷贝函数。
		
		什么时候发，出错了怎么办，这些都是传输控制层来管。
		2.发送的次数和接收的次数，没有任何关系，就是面向字节流。

		所以单单的recv无法保证传入数据的完整性。

		增加报文："length\r\nx_ op y_\r\n"  加上了报文的属性字段 -- 这样读取报文的时候首先应该读取长度即可。-这样就一定能保证读取到完整报文。length就可以利用特殊字符进行区分。 length就是正文的长度。
		此时length就可以相当于报头，属于协议之中。

	server：
		Recv：我们期望，必须返回一个完整的报文。
			我们外部定义一个缓冲区，每次去读，读成功追加。
		1读取数据 recv
			成功继续，否则结束循环
		2.协议解析。
			返回一个完整的报文。
			package = Decode(inbuffer);
			设置一个返回值，如果没有解析到一个报文就进行continue，解析到一个就可以进行反序列化了。
			Decode：
				首先一定能保证数字开头
				查看报文的大小是否包含于数据中
				-至少具有一个合法完整的报文，此时就可以动手机提取了。
				-否则返回空字符串表示没有解析到
		--此时上面的才是一个完整的协议的处理。
		
		3.保证是完整报文
		4.反序列化，字节流->结构化
		5.业务逻辑部分
		6.序列化
		7.添加长度信息，形成了一个完整的报文。
			ENCode 发 同理数据结果 - 也需要添加报文
			长度和分隔符+报文内容

		8.send发送这里 - 也需要特殊处理的 -- 能保证一次发送完么？？？在之后的多路转接的时候进行书写。
		
		
	client：
		1.获取需求
		2.序列化
		3.添加长度报头
		4.发送给服务端
		5.正常读取 - 定义一个buffer，利用上面实现的接口即可。
			读取失败，结束循环 
		读取成功，保证拿到一个完整的报文。
			循环读取这个步骤即可。
			反序列化

		sock.hpp 封装套接字

		类似于宏：using func = std::function<void()>;


--------------------------------------
守护进程：
	目前所写的全部的服务器都是前台运行的。
	1.前台进程：和终端关联的进程 -- 即该进程能否正常获取你的输入就是前台进程。-能让我输入操作东西   bash本身就是前台进程
	2.任何xshell登录，只允许一个前台进程和多个后台进程。
	3.进程除了有自己的pid、ppid，另外存在组id。
	4.在命令行中，同时用管道启动多个进程，多个进程都是兄弟关系，父进程都是bash，-可以用匿名管道通信
	5.同时被创建的多个进程可以是一个进程组，组长一般是第一个创建的进程 PGID
	6.任何一次登录，登录的用户，需要有多个进程（组），来给这个用户提供服务的（bash），用户自己可以启动很多进程或者进程组。把给用户提供服务的进程或者自己启动的进程，整体都是要属于一个会话机制中的。SID
	用户-> 登录：会话（bash（bash自己成一组）+终端  ---进程组）
	用户<-退出登录：理论上说，曾经启动的任何进程都要得到释放。--不同操作系统处理可能存在不同。
	当我们想涉及一个常驻进程 -- 即退出登录也不会退出 - 把其从原本的会话提取出来，自成一个会话。---守护进程，
	即将对应用户在当前的会话中隔离出来，这样就不会被牵连退出。
	
	7.如何讲自己编辑自成会话呢？pid_t setsid(void); -- 创建一个会话，并且称为组长。返回值成功就是谁调我，失败就是-1。
	8.但是如果setsid要被成功调用，必须保证当前进程不是进程组的组长。
		怎么保证自己不是组长呢？成为子进程。-fork()进行保证。
	9.守护进程不能直接向显示器打印消息。	一旦打印会被暂停，甚至被终止。
----------------------------------------------------------
	如何在Linux中正确写一个让进程守护进程化的代码？
	daemon -- 方法 - 就可以变成守护进程
		但是一般都是自己定制一个守护进程
		我想通过自己写一个函数，让我们的进程调用此函数，自动变成守护进程。


Daemon.hpp
	MyDaemon()
	// 1 忽略信号:SIGPIPE, SIGCHLD
	signal()SIG_IGN
	// 2 不要让自己成为组长
	fork()
	// 3 调用setsid
	setsid();  // 成为新的会话
	// 4 标准输入，标准输出，标准错误的重定向
	int devnull = open('/dev/null', O_RDONLY | O_WRONLY);
	if (dev > 0)
	{
		dup2(0, devnull);  // 标准输入重定向到devnull中
		dup2(1, dev);
		dup2(2, dev);
		close(devnull);
	}
	
	ls /dev/null null文件 - 类似文件黑洞，不影响系统的正常运行
	
	kill -9 pid 即可删除
 	使用nat.. 命令可以查看TCP服务器哦
		TTY：和终端有关吗？  -？   守护进程ppid是1类似孤儿进程
	

xshell 指令
sz -发送到桌面
rz -接收
	
	
1.序列化反序列化
2.定制了自己的协议
3.将我们的服务守护进程化。
--------------------------------------------
使用成熟的方案-别人的方案：
	针对序列和反序列化:
		json - 网络通信的格式，帮助我们对数据进行序列和反序列化。
		{"key": "value", .....}
		面对的永远是结构化的数据。
			可以发现结构化的数据本身就是key-value的。a.x = 100-- a.x(key) 100(val)
		C++使用jsoncpp这个库
		sudo yum install jsoncpp-devel
	
	jsoncpp/json/json.h  -- 头文件   + 编译链接 -ljsoncpp	ldd 可执行程序 -- 查看依赖的库

		Json::Value root;  // 万能对象 能够引用任何对象
		
-----------------------
库的使用方法

key - value

int a = 10;
Json::Value root;
root["a"] = a;
// 序列化：
1. 
Json::StyledWriter writer;  // 调试的时候查看		
2.
json::FastWriter writer;  // 格式和上述的不同   更加精简

string s = writer.write();  // 自动转化为字符串的序列化的风格	

// 反序列化
Json::Value root;
Json：：Reader readr;
reader.parse(str(字符串), root);  // 写到root Json对象里即可。
a = root["a"].asInt();  // 当做整型  - char也是整数方式取出
		

killall  进程名 杀完
-------------------------

	然后对上述自定义的序列化格式进行初始化即可。


-------------------------------------------------------------------------------------
应用层：就是程序员基于socket接口之上编写的具体逻辑，很多工作都是和文本处理相关的！--协议分析与处理。
http协议，一定会具有大量的文本分析和协议处理！

--------------------
认识URL-
俗称的网址。
协议名://域名  /.../.../(web 根目录)

https 当代主流的协议。
域名：服务器地址。实际上就是ip地址，多做一步：进行域名解析。（浏览器弄的）先有域名，-（先有公司）域名和ip地址关联起来。
	ip: 端口
端口号这里一般是被省略的。我们所请求的网络服务，对应的端口号是众所周知的。（指所有的客户端）-默认采用的端口号，和服务有关，http对应是80端口，https是443端口

-web根目录：
我们平时上网常规的行为有什么？
	1.我们想获取什么东西。一张图片、视频、文字等等 -- 资源 没有拿到的时候资源就在对应的服务器上。（Linux）
		-一个服务器上可能存在很多的资源。-文件 -- 请求资源拿到你的本地--服务进程打开你要访问的文件，读取该文件，将该文件通过网络发送给客户端。->打开这个文件，先找到这个文件。Linux中表示一个文件是通过路径进行标识的。此时web根目录 ：/ 就是文件分隔符，完全就是Linux下的文件路径。

	2.我们想上传什么东西。
四个字段：
协议名称://ip(服务器的ip地址)[:80/443] /a/b/e.html
	互联网中唯一的一台机器  唯一的进程  客户所想访问的资源路径  e.html就是客户想要的文件名
						客户所需要的资源

URL-> 定位互联网中的唯一的资源。统一资源定位符。
世界上所有的资源，只要找到其URL就能访问该资源。
www，万维网



细节：
1.web根目录是否绝对路径呢？
2.URL出现特殊符号？

urlencode
	如果用户想在URL中包含本身用来作为特殊字符的字符，URL一般形成的时候浏览器会自动的进行编码encode	? / .....

urldecode
	一般服务端收到之后，需要进行转回特殊字符。
	转义的规则：字符转化为16进制（ASCII），取4位，每2位左做一位，加上%，编码为%xy格式
	在线编码解码：

-------------------------

客户端client		cs模式					服务器端server
		（交互的就是双方通信的报文）
		->http request
		http response<-
			http的协议是应用层的协议，底层采用的是TCP
		在通信之前，已经经过了三次握手的过程
		
http：
1.快速构建http请求和响应的报文格式
	单纯在报文角度，http可以基于行的文本协议。
	请求格式request：
		请求行：方法 url(如果没有目的的地址，会访问/ 默认的路径) 请求协议版本(http/1.1)\r\n  (中间是空格分隔)
		请求报头（本次请求的相关属性）
			key: value\r\n
			......
			6~8个请求行构成
		空行	\r\n (只有这个内容)
		请求正文（可以没有）
	
	响应格式response：
		状态行：协议版本(http/1.1) 状态码 状态码描述\r\n  (中间是空格分隔)
				（状态码常见的就是404 - not found）
		响应报头（本次响应的相关属性）
			key: value\r\n
			......
			6~8个请求行构成
		空行	\r\n (只有这个内容)
		响应正文（视频、音频、图片、html......）

如何看待？
	看http请求和响应是线性结构-字符串结构哦：
	\r\n 遇到此不就是按行成列的即可。
	tcp进行互相转发	

简单理解：
	协议版本：
		client->server client用的是什么版本
		server->client server用的是什么版本

	url：想访问什么资源

	
建立一个共识：
	该协议如何封装报头-封装、解包
		http如何区分报头和有效载荷的呢？
		\r\n 通过空行的方式区分报头和有效载荷的。一定能够把报头读完->接下来在读就是正文了。-> 我们如何得知正文的大小呢？（报头中就存在一个属性——Content-Length: 123） 就可以知道正文是有多少字节即可。
		

2.http demo程序

见一见 http请求 && 响应
HttpServer
	属性：
		监听套接字
		服务器端口
		函数对象
		// 服务器ip  // 不带，使用默认即可
	构造函数：
		传入端口
		利用Sock-封装的TCPsock套接字端口
			创建套接字
			绑定
			设置套接字为监听状态
		
	析构：
		针对监听套接字即可

	start:
		循环
			服务端设置信号子进程退出 捕捉 SIGCHLD + IGN
			与客户端套接字连接 - accept
				连接不成功continue
			利用子进程去处理任务
			关闭对应不需要的套接字

public：
	using func_t = function(void(int));




http请求处理函数：
	// 1.读取请求 for test
	char buffer[10240];	
	ssize_s s =recv(sockfd, buffer, sizeof(buffer) - 1, 0);  // 阻塞读取
	if (s > 0)
	{
		buffer[s] = 0;
		std::cout << buffer << '--------------\n' <<  std::endl;
	}
单纯的读取。不关心细节
只关心http数据即请求是如何的。
测试：
	浏览器输入ip地址:端口号
	-d但是此时服务端不会发送信息。
	

请求行：
GET / (默认) HTTP/1.1
请求报头：
host：这次请求的目标ip和端口
.. 
.. 时间
User-Agent: 发起这次请求的客户端
Accepy：可以接收什么数据
接收的语言格式：
编码压缩：
空行
	
	// 2.试着构建一个http的响应。
	string httpResponse = "HTTP/1.1 200 ok /r/n"  //一般状态码成功就是200
	httpResponse +=  "\r\n";  // 这次没有所谓的响应报头。
		// 浏览器-实现难度仅次于操作系统
	httpResponse += "<html><h3>hello </h3></html>";  // 不要在代码里写这个
	send(sock, http, size(), 0);
	
telnet ... TCP连接工具
GET / http/1.1
	
	
	首先将资源访问可以设置一个默认路径下。
	
	请求的时候所谓的根目录：默认让用户去访问”
	wwroot/index.html
	
	使用C++的文件打开操作ifstream  -- 
	


3.逐步细化内部细节

	
util.hpp工具类

一般http要有自己的web根目录。
如果客户端只请求了一个/ ,我们返回一个默认首页
	http服务器端有一个默认首页	


可以写一个静态的网站了。

http本质就是文本分析。


请求行内的请求方法：
	上网行为：
	1.从服务器端拿下来资源数据。
		GET方法，获取方法(也可以提交)
	2.把客户端的数据提交给服务器。
		POST方法，提交方法
	--进程间通信

	一般就是这两种，不支持很多方法-为了防止出现漏洞。
		telnet www.baidu.com 80
		GET / HTTP/1.1
		获取首页源代码
	html（前端-不考虑服务器）
	html表单：->收集用户数据，并且按照一定的方法吧用户数据推送给服务器。表单中的数据，会转化为http request的一部分。
		表单一单提交，需要指定GET或者POST方法，action提交给哪里
		input输入框 - 密码账号输入框

	
	GET：
		URL：请求的资源？参数 （将参数提交给资源，参数中间用&分割）name=value
		通过URL向服务端传参，并且会回显到浏览器。
	POST：
		URL后面没有参数。
		参数放在了正文部分。
	
	->先使用表单。
	GET方法通过URL传参，因为在http的首部，大小方面受限一些。回显输入的私密信息，不够私密。
	POST方法通过正文提交参数的，不会回显，一般私密性是有保证的。注意私密性不是安全。对数据加密和解密才能是安全的。
	一般内容大，使用POST方法。


http响应返回的状态码：
	需要对照表
	1XX  信息性状态码
	2XX  请求正常处理完毕。
	3XX  需要进行附加操作以完成请求
	4XX  服务器无法处理请求
	5XX  服务器处理请求错误

	状态码 - 状态码描述

	3XX 重定向：进行某些网站的请求时，需要跳转到其他网站资源等。
		永久重定向301和临时重定向302（307）。
			临时重定向：不影响用户后续的请求策略。登录界面->页面
			永久重定向：影响用户后续的请求策略。域名发生变更......

	client	        Server
	|httprequeset ->|
	|http/1.1 302 Found	 <-| 告诉新的地址    （301的更新一下本地的缓存，比如更新本地书签等等）
	|->向新的地址发送请求|
	|<-返回资源|	
	 		
	状态码首先可以利用telent工具进行验证
		
		http/1.1 302 Found
		报头属性：Location: url->(重定向的URL)
		....


http的报头属性：（Location就是一个）
	Content-Length: 正文长度	表达正文有多少 - 类似于序列化过程中的用于读取
	Content-Type: 正文类型	比如图片、网页--根据发送的请求url中的后缀进行识别 -需要对照表 比如网页：text/html\r\n   ---浏览器实际上是可以识别出来的，但是有些浏览器不行。但是指定类型的话，浏览器会用指定类型进行渲染。
		图片资源，使用html<image> ,如果是本地图片,那么需要加上类型
	User-Age  -显示用户的设备信息
	referer:当前页面是从哪里跳转过来的
	*Cookie:客户端存储少量信息,实现会话(session)的功能.
	......

 
会话管理:
	http的特征:(底层:TCP套接字)
	1.简单快速
	2.无连接(TCP是维护连接的)
	3.无状态(不知道历史状态 - 即不会对用户的任何行为不做记录) 比如如果不记录状态,那么登录跳转后页面又如何知道我是登录状态呢? 但是实际上我们进行使用的时候,一般网站是会记录下我的状态的.
		http只需要保持网络功能就可以了.


http-两个报头属性-请求和响应均有
Cookie:
Set-Cookie:
	           C->密码\用户名 S   用户名\密码 - 认证是否正确
文件或者内存文件C<-认证成功-	S
用户名\密码等保存C->自动携带S	往后用户就不需要重新输入了,自动认证了.
(浏览器)	          C->自动携带S
-cookie文件	           ......
如果被清理掉,那么就需要重新登陆了.


		但是,如果客户端,被植入了木马程序,如果cookie文件被盗取了 - 个人信息严重泄露了.
		
所以,在如今的网络环境下,上述方案不安全,不可取了.
主流方案:会话保存工作全部交给服务器。

		C用户名+密码->S		用户名+密码->认证
					使用算法帮我们形成一个唯一ID - 私密信息 session id
cookie	                          C  <-唯一idS				是维护在服务端的
session id		C->http request 唯一id S		
		
		-此时黑客拿到的是session id，再次进行访问一样的能够去访问。但是个人信息是不会被泄露的。cookie文件 - 拦不住。但是服务端存在检测，比如ip突然发生变化，就让原本的session id失效，需要重新登录或者给此id定时，一定时间后失效即可。
		set-cookie - 设置一个cookie 目前只能简单演示。


Connection:keep-alive	长连接
Connection:close		短连接
	一张完整的网页，有非常多的资源构成的。
	短连接-就是每次请求都要连接一次，成本有点高
	长连接达到提高效率的目的。

http是基于TCP的。
工具：Postman、向任何网站发送请求
fiddler工具  抓包工具   http 本机的http请求全部抓取到
	fiddler-抓包原理：
		电脑	         fiddler     ->  服务器		
		浏览器 -> (劫持)	        <-
	


	如果明文的，被抓包就是不安全的，所以需要-https
	http携带数据是明文的，那么如果是私密信息，容易暴露。
	但是http因为不做安全保护的话，效率会更高。
---------------------------------------------------------------
https - 主流协议
	
安全：加密+解密
如何理解安全？
	网络安全。
	安全：破解的成本远远大于破解的收益。
	
http和https关系：

	网络协议栈：
		1应用层：http  、http+TLS/SSL:软件层，可选的，一般负责加密和解密(安全层) =  https
	         套接字编程 - socket
		2传输层：udp tcp	
		3网络层：ip
		4数据链路层：mac
		5物理层

		TLS/SSL 在网络中经过加密的，被恶意盗取后无法被使用。

	-应用软件开发：https涉及的知识非常多。工作方式了解即可。

加密和解密需要中间数据 - 密钥。
	http明文传输，容易遭到中间人攻击，即在传输过程中劫持。

加密方式 - 数学相关
1.对称加密
	但密钥系统加密。同一个密钥对信息进行加密和解密。
	DE3、3DES、AES....
	特点：算法公开、计算量小、加密速度快、加密效率高。
	明文->密文->明文
	      单个密钥
	小例子：按位异或
	a = 1234 key = 8888   a^ key  = 9834    b密文  b^key  = a

	a ^ a = 0  a^ b = c  c ^ b  = a


2.非对称加密
	需要两个密钥进行加密和解密。公开密钥、私有密钥。
	常见的非对称加密算法：RSA DSA ECDSA
	算法强度复杂、加密解密速度没有对称加密快。
	公钥和私钥是配对的，缺点就是运算速度非常慢。
		私钥和密钥随意选择。公钥就是明文传输在网络上的，私钥就是自己保存好。公钥-明文->密文-私钥-明文，可以反着来。
	

数据摘要&&数据指纹：
	利用哈希函数，将原始文本转化为一串固定长度的字符串。-数据摘要（数据指纹）。哈希存在特点：任意文本经过hash都是不一样的。
	md5
	hash在本地形成摘要。上传文件之前，先上传指纹摘要。搜素的如果没有，那么就是唯一的，慢慢往上传，如果找到了，那么就直接秒传了。

	密码->摘要
	登录：用户名+密码


数字签名：
	摘要经过加密，得到数字签名。
	数据摘要严格意义上不属于加密，因为无法解密。摘要保证与原始文本一致性的。

https的工作探究：
	1.方案1：使用对称加密
		如何保证密钥如何让客户端和服务器都拿到密钥？
		密钥如果明文传输，那么就存在问题，就没有任何区别了。
	2方案2：以非对称加密加密

		C		S
		|      ->		|
		|     < - 公钥p            |保存了私钥s
		|公钥加密->密文	|私钥解密
		......+

		但是好像只是客户端到服务器完成了加密操作，但是如果客户端接受服务器端怎么办呢？
		所以方案2也不行。

	3.方案3：双方都使用非对称方案：
		C		S
	私钥c	| ->公钥c		|	私钥s
	公钥s	|<-公钥s		|	公钥c
		|公钥s加密->密文	|私钥s解密
	私钥c解密	|密文<-公钥c加密	|

		          中间人M

		可行，中间人只有公钥，好像无法对数据进行破解。
		-但是，效率非常低下。
		-依旧存在安全问题。

	4.方案4：非对称加密+对称加密
		C			S	公钥s 私钥s
	公钥s	|->https请求		|		
	对称密钥x	|公钥s<-			|
s->x加密 -密文	|->加密的对称密钥		|私钥s对其解密->x 对称密钥     对称密钥x
		|之后采用对称加密算法传输	|


			中间人
		公钥s   拿不到对称密钥

	-此时即安全又快速。
	但是方案234存在共同的问题。我作为中间人，在一开始攻击会不会出现问题呢？
	中间人攻击-MITM攻击：
		C			中间人				S	公钥s、私钥s
		|->							|
	公钥M	|M<-		截取s，保存s,对其进行修改为自己的公钥M	        s<-   |
（以为是对面服务器的）		
形成自己的对称密钥x	|->M加密的对称密钥	  利用自己的私钥M解密，然后利用公钥S加密发送 ->|私钥s解密获得对称密钥x
利用的是公钥M进行加密			中间人获得了对称密钥x
					。。。。。。
		|------------------双方蒙在鼓里，以为安全的，实际上全部都泄露了-------|

		所以只要传递公钥，只要存在中间人拦截，中间人完全可以攻克。
		但是我们只要交换了密钥了，中间人来了就晚了，但是中间人最开始来了，就可以进行篡改替换。
		这个中间人攻击能成，本质是什么呢？-1本质是中间人能够对数据进行篡改。2客户端无法验证收到的公钥是合法的，即是不是对方服务器的公钥。
		
		
	
	CA认证：
	-为了解决上面的问题，client需要对server的合法性进行认证。
	权威机构--CA机构、颁发证书--CA证书。

	2.审核
	CA  3签发证书
	1.申请认证	
	server	4返回证书		client5.验证证书	
		6密钥协商
	
	理解数据签名。
		签名的形成是基于非对称加密算法，目前和https没有任何关系。
	签名：
		数据 散列函数->散列值
			签名者的私钥加密
			签名 - > 数据+签名  --认证数据    携带签名的数据。

	验证：	分开
		数据	签名
		哈希函数	签名者的公钥解密
		散列值	散列值   - > 对比 没有差别说明是正确的，如果发生了修改，那么就是错的。

	签名者的私钥就是CA自己的私钥。

	5.方案五：

	CA如何签发证书的：
		CA机构也有自己的非对称密钥，公钥A，私钥A'
		明文信息 - hash-> 数据摘要 -使用自己的私钥进行加密->数据签名
		明文数据+签名数据---CA颁发给server的证书。

	

	C						S 证书
	|->
证书	|<证书-
提取到	|->加密X						| 
公钥s	|
加密对称密钥X.....	
	
	能解决上面234的问题吗？
	1.中间人能否对发来的数据进行篡改呢？2.客户端对服务器端的公钥进行认证。
	中间人可以截获证书，本身明文发送的。
		自己的非对称密钥M M' - 修改的是明文数据  没有CA机构的私钥，就无法形成匹配的签名。无法造假证书。
		将里面的公钥替换成中间人的

但是客户端在提取公钥之前，需要进行证书认证。签名数据->利用CA的公钥（中间人无法对签名数据进行修改）解析出哈希值 然后与明文数据使用相同的哈希算法形成哈希值，查看相等就可以知道是否被篡改了。
		
	每个计算机浏览器内置了很多权威的证书。
	客户端对签名做解密，只用自己内置的CA公钥。此时就不存在234的问题了。那么中间人是否可以全部替换掉了呢？虽然此时证书是真的-*（利用中间人的证书 进行全部替换）但是域名不对的。-客户端访问服务器，肯定是知道对方的域名的啊。所以无法整体掉包。

	
	如何成为中间人：ARP欺骗、ICMP攻击、假wifi&&假网站
	
	https 三组密钥：CA非对称加密		服务器端非对称密钥		对称加密
	问题的关键是对对称加密展开的，能够人双方安全可靠的被识别。
	CA是为了保证服务器端公钥的合法性
	服务器端公钥保证了对称密钥的合法性。


----------------------------------------------------------------------------------------------------
传输层

在谈端口号：
	之前的经验，服务器需要显示的绑定。
	在TCP/IP中，除了源目的 ip port还有协议号这样五元组来标识一个通信。
	
	netstat -nlt	可以进行查看 - 查看使用什么方式进行通信。
	IP首部+协议  port首部

端口号范围 16位整数：
	0 - 1023：知名端口号，http、FTP、ssh这些广泛的应用层协议，其端口是固定的。
	1024 - 65535：操作系统动态分配的端口号。客户端程度的端口号，就是由操作系统在这个范围里划分。

	-http 80 https 443  telnet 23 ftp 31 ssh 22  -- 可能不止一个

	建一个服务，一般以d结尾的就是守护进程。
	使用端口的时候，尽量避免这些知名端口。
	端口号找到对应进程是通过哈希表的。

netstat的使用。
	查看网络状态的。
	-n能显示成数字
	-T、U TCP UDP
	-l listen状态的服务
	-p 查看其进程状态。
	-a 全部显示出来（有些默认不显示）
	
	pidof 查看服务的pid  
		pidof server | xargs kill -9
		注意进程的标准输入和命令行输入  此时管道传入给kill是标准输入，利用xargs将标准输入的内容转化为命令行参数的内容。
	

-----------------
UDP协议：
	应用层			--之前所写的很多代码均为应用层的服务。标准的：http..... 自定义的：计算器
	传输层	-属于内核的	UDP、TCP	端口号就要在这里起效了。
	网络层	-属于内核的	
	数据链路层 - 驱动程序
	

	1.几乎任何协议都要首先解决两个问题：a如何分离（封装）。b、如何交付。
		先将报头和有效载荷分离。
	2.理解udp、tcp报文，理解报文本身
	3.具体的报文字段。		

			udp报文：
			报头：源端口号、目的端口号 前八个字节
			有效载荷		
	采用的固定长度的报头。（将报头和有效载荷分离，并且提取目的端口号）
		根据报头中的16为端口号进行向上交付，进程bind端口号！-约定好了的，这就是协议。
		-为什么我们在应用层写代码的时候，端口号为什么喜欢uint16_t 位的 4字节
		-udp如何正确的提取整个完整报文的。固定长度的报头。16位数。
		-然后减去这个长度就可以读到有效载荷了。
	
	udp是具有将报文一个一个正确接受的能力的。->udp是面对数据报的。

	实际上udp的报头：struct udp_hdr {uint32_t src_port:16; uint32_t dst_port:16; udp_len:16; udp_check:16};
									// 报文长度
		应用层->内核层 将数据拷贝过来，然后将结构体也拷贝过来  -- 封装好了形成报文。
		--利用位段进行构建。
	解包的话：(struct udp_hdr*)start->src_port;...... 提取出报头的每一个字段，然后就可以分离载荷，根据port向上交付给应用层进程去。
	-内核操作：并且此时可能存在大量的报文。此时就要进行管理起来，即内核数据结构sk_buff。进行收集管理。
	
	3.具体的报文字段。：
		0 	15 16		31
		16位源port      16位目的端口号
		16位UDP长度   16UDP检验和
		数据
		
		-此种约定必须被双方知道。

	udp的不可靠、无连接
		丢包，没有确认和重传机制，网络故障无法提示对方。 - 代码一定非常简单，成本低，在有些情况下就可以使用。
	面向数据报：
		应用层发给传输层多少数据，原样发送，不会拆分，也不合并。

	4，如何理解sendto、recvfrom、read、write等IO接口呢？
	用户层	send  recv	这些函数本质是拷贝函数-拷贝到内核中的缓冲区 - 反过来同理。
	-------
	内核层
				缓冲区一般都是传输层协议提供的。
				而什么时候发，发多少，出错了怎么办 - OS关心。-也是传输层协议自主决定的。


	udp的缓冲区：
		udp没有具体的发送缓冲区，调用sendto会直接交给内核。
		udp具有接受缓冲区，但是不能保证收到的udp顺序和发送的顺序一致，缓冲区满了就会一定丢弃。-udp特征可以利用快递进行类比。
		udp的socket既能读也能写，叫做全双工。


	-5.全双工和半双工：
		全双工：可以两个缓冲区（发送和接收）使用，互相不影响。半双工：要么听要么写，只能执行一种。
	
	udp的注意事项：
		2^16次方 - 长度 64k(包含UDP首部)，在当前互联网环境下是一个非常小的数据。-传多个，分包，自己手动拼装。
	
	DHCP协议 - 动态分配ip

	
----------------------------------
TCP协议：传输控制协议。
	1a如何分离（封装）。b、如何交付。
	2回顾一下如何理解tcp报头，位段
	3重要的可靠性属性，作为切入点 - 什么叫做可靠
	4系统学习tcp报头
	5tcp可靠性的其他策略。



	0		1516		31		标准长度20字节
	源端口号		      目标端口号
	32位序号
	32位确认序号
	4位首部长度 保留6位    6个标记位  16位窗口大小
	16位检验和	紧急指针
	选项
	数据

	1.交付自然是根据目标端口号 - 查哈希表找到其进程 ， 将数据拷贝到文件缓存区内，被上层所调用。
		前20个字节 - 报头。注意报头是可以变长的。
		4位首部长度 - 1111  0， 15：单位是4字节。理论上是0 - 60字节。 x * 4 = 20 ~ x*4 = 60  -- [5, 15]4位首部长度就是0101 - 1111 - 表示报头+选项的长度
	解包：1.提取二十个字节 2 根据标准报头提取四位首部长度 * 4 = 20 - done  读取选项  3 读完了报头，剩下的就是有效载荷。
	问题：TCP是没有整个报文大小或者有效载荷的大小的。 -- TCP是面向字节流的。原则上无法判断报文和报文的边界。-此时该如何被解释，是应用层该操心的事情。

	2.同UDP一样，位段 - 将统一的类型 - 结构 内核中就是被解释为了一个对象，就可以被拷贝。强转，提取其中的数据。
	

	3.重要的可靠性属性，挑一个最重要的，作为切入点 - 什么叫做可靠
		比如两个人之间对话。如果距离近，那么会通信流畅，但是距离远了，通信不流畅了，成本增加（需要重复去说），可靠性减少。 原因就是距离变长了。
		操作系统单机内部不谈TCP/IP协议
		一旦涉及到网络，TCP/IP 可靠性就是一个人发出的消息，对方收到了。
		
		1.网络中，存不存在100%可靠的协议呢？-自然不存在。因为无论是双方主机，无法保证自己作为最新发送数据的一发被对方收到。但是，在局部上能做到100%可靠：当一个主机收到应答了，就能保证上一次发送数据是可靠的。 -也就是保证历史的可靠性。-本质就是我发送出的所有消息，只要有匹配的应答，能保证我刚刚发出的消息对方一定收到了。TCP协议的确认应答机制：但是只要一个报文收到了对应的应答，就能保证我发出的数据对方收到了。TCP三次握手。
		2.但是无法保证不可丢包，我只能识别出来，并且保存上次没有丢包的数据。

	客户端						服务端
	|一次向对方发很多个独立的报文	->			-原则上应该每一个都要进行独立的应答|
	|此时可以保证可靠，不存在就重发	<-发送应答	|	（客户端发送很多报文，发送的顺序不一定是接受的顺序。-这也是不可靠 - 数据包乱序。客户端收到应答后，怎么确认哪个应答对应哪个请求？）
		往往给对方发消息也就是应答。

-引入概念：序号
	注意发送的报文可不是单纯的字符串，而每一个报文一定携带了完整报头的TCP报文。所以包含了32位序号。比如第一个报文序号是1000，第二个2000，第三个3000。发出去后给应答，server给应答后一定会给序号，并且会在基础上加1.比如收到的就是确认序号： 2001 1001 3001 此时就可以将请求报文和应答报文对应上。（确认序号表示：对应的数字之前的报文全部收到了，告诉对方下次就从确认序号指明的序号进行发送  ）
	1.将请求和应答一一对应。
	2.确认序号表示的含义：确认序号之前的数据已经全部收到 - 客户端不怕部分丢包了。
	3.允许部分确认丢失，或者不给应答。
	4.为什么要有两个字段数字？TCP是全双工的。任何一方即可能收，也可以发。任何通信的一方都是全双工的，在发送确认的时候也可能携带新的数据。
	5.乱序是不可靠性的存在。但是已经解决了，因为报文中的会携带序号，只需对多个序号进行排序，就可以按序到大了。
	可靠性：顺序 + 丢包

-保留六位：报文中暂时不用
-16位窗口大小：

	client				
	应用层：							应用层：
			write    recv......（全都是向底层缓冲区要的）					
	TCP：发送缓冲区			-网络-			TCP：发送缓冲区
	         接受缓冲区						         接受缓冲区
	
	TCP解决的问题就是如何发送的问题，-传输控制协议-。TCP通信本质就是发送和接受缓冲区进行来回拷贝 - 拷贝的介质就是网络。TCP有发送和接受缓冲区，有client和server就有两队接受和发送缓冲区。是独立的进行发送和接受，所以TCP就支持全双工了。
	注意双方速度存在差异，需要进行同步调节。
	
	如果发送方发送数据太快，就应该让发送方慢一点 - 应该多慢呢？-发送方发送数据，既不能太快，也不能太慢。-如何进行保证？ - 当应答的时候，应该给发送方同步自己的接收能力。我的接收能力由什么决定？-接收缓冲区中剩余空间的大小。这也就是流量控制。
	16位窗口大小，也就是剩余空间大小。并且此窗口大小是谁发的，就是被发者填写-是要发给对方的。对方根据此大小来调节对被发送方的速率。
	是双方的流量控制。-报文交换。

-6个标记位（标准：6个比特位）
	1bit表示某种含义的。
	为什么需要这么多标记位？
		因为client可能给对方server发送不同类型的报文：常规、建立连接、断开连接、确认等报文（反过来同理）
		需要注意，不同的报文处理的方式是不同的。比如建立连接 - 对此链接进行处理，断开就要进行释放。所以服务端可能会收到大量的不同的报文。
		所以标记位的本质就是标记报文的。

	各个标记位有什么含义？
		SYN：该报文是一个链接请求报文。
		FIN：该报文是一个断开链接请求的报文。
		ACK：确认应答标记位，凡是该报文具有应答特征。（要么应答(只发一个报头)，要么除开应答之外也要发消息-大部分网络报文ACK都是被设置为1的）（当然也存在不应答的，比如第一个建立链接请求报文）

=TCP建立链接和断开链接：三次握手，四次挥手。

	因为有大量的client将来可能链接Server，所以Server一定存在大量的的链接 - OS需要进行管理。先描述在组织。

	1.如何理解链接？
		本质是内核的一种数据结构类型，建立连接成功的时候，就是在内存中创建对于的链接结构对象，在对多个对象进行某种数据结构的组织。
		维护链接是有成本的 = 内存+CPU			

	2.如何理解三次握手？

		C			S
SYN_SENT发送	|1-带有SYN的报文->		1|
		|	           <-SYN+ACK-2|SYN_RCVD 收到
ESTABUSHED	|3-ACK->			3|ESTABUSHED成功
		|			|
		|			|
(注意线应该是倾斜的，即时间 - 会晚一点)				
(注意发的全都是完整报文！只是有限不存在数据-有效载荷而已)
	是对客户端和服务端都要起效。（各自都要三次）
	注意，三次握手不一定要保证成功。-可靠性是建立在链接成功后的状态。注意最后一个ACK的报文发送后不一定保证其一定能收到的。
	对于client，最后一次一旦将3发送出去，就需要将此状态置为ESTABUSHED。对于前两次，一定保证不丢包（存在应答，如果没有，会触发后续的处理）。但是实际上，3可能对方不一定收到。-所以可能失败。只有服务端真正的变为ESTABUSHED状态，才能建立成链接。
	-为什么要三次握手？
		如果是1次握手 - 那么发送一次，server就应该建立一次链接。但是server维护链接是有成本的。如果客户端发送多次，那么服务器很可能直接挂掉。（SYN洪水） - 但是实际上三次握手也不可防止这种类似的轰炸，只不过成本变高了。
		两次？类似第三次发送，服务器无法得知客户端是否知道了或者恶意丢弃.但是此时链接已经建立了。所以类似第一次的那种攻击，一样的容易让服务器挂掉。
		三次的话，可以发现，发起连接的需要完成一次应答。即完成一次应答，发送的端率先进入ESTABUSHED状态，server只有收到应答后才会建立ESTABUSHED状态。时间会往后推。这样的话，像之前的两种攻击客户端对于服务器的支出成本客户端偏低。而现在，客户端的成本是偏高的-如果攻击成功，那么就是同等的资源支出。不能杜绝，但是可以有效的抵御。注意之前是指单机攻击成本。
		实际上安全保证还是应用层上进行相关措施的，三次握手的目的并不是为了安全，1.而是在进行建立连接的过程中顺便让客户端能够承担于服务器端一样的压力。
		2.验证全双工。比如打电话的时候说喂。
		奇数次握手：压力偏向发送方。
		
	有可能，如果第三次发送的ACK服务器没有接收到，如果客户端瞬间发送消息 - 此时服务器接收到了，因为没有建立连接成功 - 服务器会向次客户端发送RST-连接重置。当然这里只是简单的举例，实际上出现机会很小。
	如果服务器向客户端发送报文的16窗口剩余数据为0，然后如果客户端反复等待，会发送带有PSH的报文，催促服务器尽快向上取走。



		RST-连接重置 重新进行tcp建立连接。 - 情况主要发生在连接后，服务器重启，客户端不清楚，仍在发此时服务器就会发送这个。
		PSH：督促对方尽快将数据进行向上交付。
		
	因为tcp是具有按序到达机制的（优点）。我们发送的数据的时候，被对方上层读取到，必须有顺序。但是如果想插队呢？
-16位紧急指针
		URG：紧急标记位，配合16位紧急指针。
	如果此时报文有URG了，那么通过机制，读取16位紧急指针的位置，尽快的向上交付。16位紧急指针指向的是：在有效载荷中的偏移量。并且只是一个字节的数据。一般用于机器-系统管理，而不是正常的业务处理。
	

	3.如何理解四次挥手？
		
		C			S
SYN_SENT发送	|-带有SYN的报文->		|
		|	           <-SYN+ACK-|SYN_RCVD 收到
ESTABUSHED	|-ACK->			|	成功
		|			|
		|-.......			|
		|		           .....-|
FIN_WAIT_1	|-FIN（client不会再发送数据了）->| 一般是操作系统进行的，容不得你TCP   CLOSE_WAIT
FIN_WAIT_2(关闭通道)|             		    <-ACK-|
TIME_WAIT	|		     <-FIN-|LAST_ACK
	-此时这两个标记位可以压缩成一个报文所以四次挥手可能变成三次挥手！-
		|-ACK->			|CLOSED
等待一段时间：CLOSED
		）
		断开链接双方都有可能。是两个人的事情。


	-什么是TIME_WAIT 和 CLOSE_WAIT？
		如果我们发现服务器具有大量的	CLOSE_WAIT状态的链接时候，原因是什么？-没有发送FIN。即应用层写的有bug - 忘记关闭对应的链接sockfd。-此时就是泄露了，没有释放此链接。
		-可以进行证明：：：服务器端不关闭服务套接字，客户端主动关闭，就可以利用netstat -atp查看到此状态CLOSE_WAIT
		反过来验证TIME_WAIT 让服务端主动断开连接，当然，如果直接终止进程，那么也就是自动的服务器端发起四次挥手，那么最后先变成TIME_WAIT，虽然四次挥手已经完成，但是主动断开连接的那一方需要维护此状态一会儿时间，连接已经结束，但是地址信息 - ip、端口依旧是被占用的-此时无法被绑定的。时间根据操作系统的不同而定。
		-需要让服务器能够立即重启的能力 - 因为存在问题！！！
		系统提供了一个接口：
		setsockopt - 设置套接字的属性：
			可以让操作系统直接
			opt = 1; // 打开
			setsockopt(sock, SOL_SOCKET, SO_REUSEADDR|SO_REUSEPORT, &opt, optsize);
			此时服务器就可以立即重启了。-设置了地址复用。也就是可以再timewait之间立即启用。	
	-为什么需要TIME_WAIT这个状态呢？
		可能存在一些报文滞留在路上，（在四次挥手期间）单向传输时间的最大时间 MSL，等待2MSL可以让网络的历史数据进行消散-双方被丢弃或者接收。因为有可能重新进行连接：历史上此时存在数据，可能会影响双方的通信。所以尽量的保证网络包的消散。当然也只是预估的时间，并不能百分百进行确定。（MSL在RFC1122中规定2分钟，centos默认配置时间为60s，cat /proc/sys/net/ipv4/tcp_fin_timeout 进行查看  MSL是报文最大生存时间）当然，也可以理论上帮助最后一个ACK被送达。（这也是概率问题）

		当然，还是和服务器端有一些原因。如果直接进入CLOSED状态，那么最后一次发的ACK没有被接收到，服务器端没有接收到会重传FIN，此时无法接收到了。虽然最后也会关闭。但是能够准确的在一定时间里进行关闭。

	断开连接一定能成功嘛？

TCP的机制：
-TCP的可靠性、效率提升问题--------------------------------

确认应答(ACK)机制：
	报文 - 数据段（报头 + 数据(有效载荷)）
	只要保证a->b ，a收到了b应答，就能保证a->b的可靠性，相反同理。
	当然，因为携带序号。我们也就是能够保证发送数据的有序性，也能保证TCP的可靠性。
	-----------------
	缓冲区与序号。c->s
		-应用层-
		TCP
		发送缓冲区：[			]
		char*	     0  1  2 .......   		NUM

		理解TCP的发送缓冲区，可以将其看作一个char sendbuffer[NUM]的数组
	
	超时重传：
		发送后，发送端如果在一定时间内没有接收到指定的应答。如果超时，就认定丢弃，就进行重传。
		1.发送的数据段丢了，丢包
		2.被发送方发送的数据段丢了，应答丢了。	
	    小问题：丢包重传对方可能收到重复报文的情况。收到重复也是不可靠性的一种。解决方法就是根据报文中的序号进行去重即可。
		3.超时时间应该如何设置？自然，超时时间不可太长，也不可太短。当然不可设置为固定时间-网络好的时候，超时时间应该、会短一点，超时时间应该、会长一点
			在Linux以500ms为一个单位进行控制。每次以500ms的整数倍进行重传。1*500，2*500，4*500 指数，如果到一定次数认为链接失效，client会自动断开链接。

-------流量控制
	处理速度是有限的。发送的数据必须根据接收能力进行发送，而不是发的很多直接丢弃。
		接收端发送ACK的时候，将接收缓冲区大小放入报头窗口大小字段中。
		满了，不在发送，需要定期发送一个窗口检测数据段（就是一个TCP报头），使接收端把窗口大小告诉发送端，当然也可以窗口更新了，发送窗口更新通知。（两种策略都在使用）
		-1.注意，同样的也是双向的。-全双工的-同时做。
		-2.那么第一次发送消息的时候，我如何直到对方的接收区大小呢？-我们需要的是对方接受的能力即接收缓冲区的大小。但是问题所说的是第一次发送数据。并不是第一次交换报文。---三次握手的时候，前两次握手的时候一定会不会携带任何数据，但是可以在报头上携带接收缓冲区的大小。
	实际上TCP40字节选项中存在一个扩大因子M，实际窗口大小字段值左移动M位。
		
-----------------滑动窗口
	之前基本都是保证可靠性的。
	现在主要提高网络发送数据效率问题。
		像之前，是一种串行的操作。一次发一次应答。很慢
		那么现在一次发送大量的数据，效率就可以提高。
			1所以，发送时并行的过去，应答也是并行的发过来。IO时间重合。
			2理论上发送多少个发送应该有多少应答。
			3流量控制：允许发送一批数据（同时），当然前提是总量是小于对方接收能力。
	
	c							s	
	允许向对方发送数据暂时不需要确认，可以立马发送下一个数据
	[	【	】	]
	以及发送		 尚未发送
	收到应答   可以直接发送
        (可以善删掉)     暂时不需要应答。
			|
		滑动窗口
			1.在哪里呢？在自己的发送缓冲区中，属于发送的数据。窗口大小就是无需等应答数据的最大值。
		本质：
			发送方可以一次性向对方推送数据的上限。-滑动窗口需要遵从流量控制。==对方的接受能力决定。（既想给对方推送跟多的数据，又要保证对方来的及接受）
		
	
	滑动窗口的完善理解：-建立模型
		滑动窗口本质：就是指针或者下标。
		int win_start, win_end;

		[[][][][][][][][][][][][][][][][][][][][][][][][][][][][]]
		start		end = start+对方的接受能力
		1.滑动窗口不一定右移动。对方没有向上传，接受能力减少
		2.可以为0，也就是说对方接受能力为0。
		3.如果没有收到开始报文的应答，而是收到中间的，此时完全没有问题。（序号的含义就是）
		4.超时重传背后的含义：就是没有收到应答，数据必须要暂时保存起来。
	一个策略：根据应答的确认序号进行更新：
		更新：
			win_start = 收到应答报文中的确认序号，end = start+ 对方接受的能力(存在两个条件)
		
		5.滑动窗口如果一直向右滑动会不会越界呢？-自然不存在。
			实际上，TCP的发送缓冲区是环状的。用线性模拟环状，进行模处理即可。			
			
	
	滑动窗口是解决效率问题还是可靠性问题？自然偏重于效率问题。


		数据包丢失。
		-高速重传机制。中间存在丢失，ACK序号只能传丢失前的序号。此时传给的多个报文应答都是此序号。如果收到三个一样的，那么就会对此进行重发。
		快重传：为什么还要搞一个超时重传？当然，因为快重传必须有条件的：连续三次！而且还有可能ACK应答丢。所以并不是对立的，两者是互补协作的。
		
----------拥塞控制：
	C		<-网络->		S
		---------
		超时重传
		快重传
		流量控制
		链接管理
		滑动窗口
		去重&按序达到
		序号机制
		确认应答
		---------
			解决的是端到端的可靠性问题。
			但是别忘了，中间还要一个很大的因素：网络的健康状态
			
		----->
		1.少量丢包 - 我的问题
		2.大量丢包 - 网络的问题（网络拥塞了） - 重传吗？？？
			绝对不能重传了。此时重传了，会更加加重阻塞了。（不能局限于一个链接）

		如何去解决？
			慢启动机制。
			先一个发，收到应答，逐渐增加发送，如果收到应答就会继续发送。
			1 2 4 8......
			（同样的从宏观的视角去看）
		
		慢启动：
			拥塞窗口：
				一个TCP / IP协议栈上的数字。单台主机一次向网络中发送大量数据时可能会引发网络拥塞的上限。
			滑动窗口的大小实际上 = min (拥塞窗口的大小， 对方的接受能力);
		
			当然，一直指数增长太快了。也就是说不能让拥塞窗口加倍。引入一个慢启动的阈值。当超过阈值后，后面进行线性方式增长。放弃指数增长。（阈值也会变化，变成上次拥塞窗口的一半-乘法减小    过阈值：拥塞避免-加法增大）
		为什么拥塞之后前期时指数增长呢？
			前期慢，后期非常快。
			一旦拥塞：1.前期要让网络有一个缓一缓的机会。2.中后期，网络恢复了之后，尽快恢复通信的过程。-再慢慢的发可能会影响通信效率。
			~热恋的感觉~~
------------延迟应答
	保证效率问题。

用户层：
S			C
发送缓冲区		接收缓冲区

	<-ACK应答- 是需要同步我们接收能力的
	如果我能够给对方同步一个更大的接受能力	
-因为对方有滑动窗口，有可能允许发送方向对方发送更多的数据，单次IO的效率就会更高。
		（也取决于拥塞窗口）

如何保证给对方同步一个更大的接受能力呢？让上层将数据取走，给接受缓冲区留下更大的剩余空间。也就是说给上层一种缓冲的时间，让上层有时间处理，这样就有可能剩下更大的空间了。
	数量限制，时间限制一般N取2，时间取200ms

-----------捎带应答
	确认本身可以携带数据。不一定捎带应答，但是大多数情况下是捎带应答的。	

-------------------------------总结--------------------------------
可靠性：校验和、序列和、确认应答、超时重发、连接管理、流量控制、拥塞控制
性能：滑动窗口、快速重传、延迟应答、捎带应答

三个问题：
     --面向字节流：
	udp非常像收快递。
	TCP像自来水管。
	数据没有任何边界和区分度的。TCP不关心数据到底是什么。-是应用层自主决定的。应用层完全不用考虑什么时候发，一次发多少。

    --数据包粘包问题。
	-也就是TCP面向字节流的，如果一次读取一个报文，必须按照协议进行读取，如果不制定协议，那么可能会多读或者少读，就会出问题。
	明确报文和报文之间的边界。解决此问题就是在协议体现边界。-比如定长、特殊字符作为换行符、设定报头-标准字段，长度和有效载荷。此时就是在应用层实现的。
	
	udp协议不存在粘包问题。 - 会区分报文之间的边界。

     --TCP异常：
	进程终止，文件描述符会被释放，而此时就是正常进行四次挥手。也就是说上层应用崩掉了，不影响底层的链接释放。机器关闭（或者重启），先会终止进程。
	如果直接断电或者断网，此时会出现什么呢？
		1.被扒主机发现网络变化，会立刻断开关闭链接。
		2.存在一定的保活：建立链接后，对方长时间一直不给我发消息，认为对方可能以及关了，-会定期询问是否在，如果不在那么将链接释放。（当然，对于有些可能存在一些长链接 - 应用层可能会维护，也会定期尝试重新连接）


---------TCP/UDP对比：
TCP：HTTP/s ssh telnet fip smtp(应用层协议)

	选择协议时，根据应用场景：比如不能丢弃任何数据。-TCP，如果可以允许少量丢包，简单快速的实现 - UDP。
		

	经典面试题：
		用UDP实现可靠传输。
		按照TCP的特点回复即可。
	
	

-------------
解释listen第二个参数
	注意，accpet不参与三次握手的过程。它需要从底层直接获取已经建立好的链接。也就是说：先建立好链接，然后才能accept获取对应的连接。不调用accept，能建立连接成功。--如果上层来不及调用accept，对方还来了大量的连接，所以连接都应该先建立好吗？不可，否则服务器很容易挂掉。

	海底捞的例子：为什么要排队：保证一旦有客人离开，可以立马让外面的人进来吃饭，保证自己资源是100%利用的。队列不能没有，也不能太长。（太长了，首先等待时间长，并且成本高（不如增加自己的吞吐量））
（没有的话，满载直接拒接。如果某个服务断开了。但是无人访问，此服务器的效率不行，不是高效的）
	
	服务器本身要维护一个连接队列，不能没有，不能太长。和listen的第二个参数有关。
	
	实验测试：实验拒接连接，服务器只设置监听状态，然后死循环，不accpet（不取出来连接），设置listen第二个参数1个长度，多端连接测试。两个连接成功，第三个变成SYN_RECV ，暂时不处理此连接，也就是第三次握手没有发出 并且过一会儿还没连接那么就会被释放掉。
	参数含义：底层全连接队列的长度  = 参数 + 1；全连接用来保存est状态，但是上层没有accpet的请求。半链接队列：保存SYN_RECV和SYN_SENT状态的请求（生命周期很短）	 			
	


----------------------------------------------------------------------------------
网络层 - IP协议
应用层：（数据如何去使用的问题）
	在下三层：将数据可靠的从源主机跨网络发送到目标主机。
传输层：数据向下交付给网络层
网络层：IP协议：提供一种能力，将数据从源主机送到目标主机的能力。
数据链路层：

那么有能力的话，一定做的到嘛？-指有非常高的概率做成一件事情。
	可靠性由传输层（TCP）决定，传输能力由IP协议决定。（老板 - 员工）

	根据IP地址进行一跳一跳进行选择的。
	
主机：配有IP地址，不进行路由控制的设备
路由器：配由ip地址，又进行路由控制；
节点：主机和路由器的统称。


1.封装和分离、2，向上交付。
IP协议：
	报头
	TCP数据段		IP-TCP-http-数据
	

	报头：固定长度的报文，20byte
	选项
	数据
1.定长报头 + 自描述字段	4位首部长度 - 20字节 = 选项大小。有效载荷拷贝到后面即可。
2.8位协议：标识UDP还是TCP。将报头去掉，将有效载荷向上交付即可。


报头属性：
	4位版本：指定IPV4，4字节，32位，表示源IP和目的IP。（和IPV6并不兼容）
	4位首部长度：4个比特位-0 - 15 是存在单位的，基本单位是4字节的(0 - 60byte)。
		注意：X * 4 = 20（不存在选项）X = 5;    -0101-.
	8位服务类型TOS：3位优先权字段（弃用）4位TOS字段1位保留字段（0） -默认，了解一下。
	有效载荷 = (16位总长度 - 4位首部长度) * 4 byte.
		-- 可以很好的分离
	8位生存时间TTL：防止一个报文进行环路转发，需要设置生存时间。（互联网很大，并且设备底层可能不同，不可排除网络中存在的一些数据黑洞）如果不设计约束，那么可能此报文成为垃圾了，并且不断在转发-浪费资源。实际上就是一个计数器，每转发一次-路由器进行减减，当最后一次识别到0时，将不会被转发，直接被丢弃。
	8位协议：上层协议对应的具体协议。
	16位首部校验和：（测试报头是否正确）校验失败，直接丢弃。不怕丢弃。-上层TCP协议策略会进行重发。比如滑动窗口中进行超时重传等操作。
	32位源IP：
	32位目的IP：

IP报文的形式和TCP的报文非常类似：
	标准报头20byte，也包含选项 - TCP/IP
	
	网络层需要向下给链路层交付。由于链路层物理特性的原因，一般无法转发太大的数据。-所以链路层又一次可以转发到网络报文大小的限制（1500byte，MTU）
	那么此时大于1500，该如何发呢？-只能进行拆分，一部分一部分的进行发送即可。
	所以网络层需要进行数据分片。	之后还是由网络层进行组装。（数据链路层由于有不同的局域网-采取的底层不同，所以各有差异，既然分包，就让共有的网络层IP分包即可）
	传输层决定了数据包的大小。
	所以，网络层能发给链路层就直接发，如果不能发就进行分片。

---------------分片
为什么？分片
	-|^
是什么？
	将一个比较大的ip报文，拆分成为多个小的，满足条件的报文，分片的行为是网络层做的，同样组装的行为也是对方的网络层做。（为什么要组装？一个一个发送上去不就可以了嘛 -对方给的是一个完整的TCP报文，所以向上交付也必须是一个TCP完整报文）
	IP分片和组装的行为，TCP是不知道并且不关心的。
	
	
如何办到的：
	16位标识：IP报文的序号	
	3位标志：	1位是保留的，第二个位置1表示禁止分片。如果此时长度超过了MTU（数据链路单次最大大小），直接丢弃，第三位表示更多分片，分片了的话最后一个分片置为0，其余分片为1。（1表示后面还是存在分片的，0表示后面没有分片）
	13位片偏移：在原始报文的偏移量
	
	对于接收方来说：（组装方的网络层）
		注意：
		1.网络层最好还是不要分片。（分片不是大部分情况下）
		2.具有识别报文与报文之间的不同。
		-16位的标识，不同的报文其标识是不同的。相同报文的分片，标识也是相同的。（网络层不会出现挤压，没有缓冲区，直接交付的）+
		3.具有识别报文是否被分片了
		-a、如果3位标识中的更多分片位1，表示它被分片了
		b、如果我就是最后一个分片，更多分片标志位就是0（如何区分是分片和独立的报文呢？）-那么你的13为片偏移，一定不为0！
		-综上，更多分片为0并且13位片偏移为0，表示此报文并没有被分片。
		1、2 -- 我们收到一批报文的时候，尽可能将报文分片区分出来，放在一起。
		4.识别哪些分片是开始、中间、结尾
		-·a、开始分片：更多分片：1，片偏移为：0；结尾：更多分片：0，片偏移不为0.；中间：更多分片为1，片偏移不为0.（中间报文存在多个，如何保证收全了的）
		注意：偏移量 + 自身大小 = 下一个报文的偏移量。根据偏移量进行升序排序结合偏移量 + 自身大小 = 下一个报文的偏移量扫描整个报文如果不匹配，中间一定为丢失，如果计算到结尾的时候，就一定收取完整了。（组装过程，并且保证可靠性）		
		-区分是否收全，并且提供组装的方案。	
		5.异常处理：我们的识别如果组装过程中，任何一个分片丢失，都需要识别出来
		-能，只要发现当前偏移量+自身大小 ！= 下一个偏移量，两个如果不一样，相减就是丢失的那个分片。
		
	-demo：

		网络层	
		MTU：1500
		
		IP报头 有效载荷 - 3000byte
		IP报头[][]
		

		分片之前一定是一个独立的IP报文，分片之后，每一个分片都要有IP报头.（为了支持未来的组装，每一个分片都必须有IP报头）
		
		（报头被分片了，存在变化）
		IP报头 []	-1500byte
		16位标识：1234
		3位标志-更多分片：1
		13位片偏移：0	
		总长度：1500		

		此时剩下[] - 有效载荷 1500
		 此时该怎么办？不可添加（大小变化），也不可直接发送
		IP报头 [ (1480) 此时大小 - 1480 + 20 = 1500byte
		16位标识：1234
		3位标志-更多分片：1
		13位片偏移：1500（有效载荷在原始的偏移量）
		总长度：1500 - 20 （特殊处理，不是原始的报头，长度需要去掉）

		此时剩下] - 有效载荷20byte （目前这里不准确）
		IP报头 ] (20) 此时大小：20 + 20 = 40byte
		16位标识：1234
		3位标志-更多分片：0
		13位片偏移：1500 + 1480 = 2980（有效载荷在原始的偏移量）	
		总长度：40 

	-分片我们严重不推荐，分片的坏处：
		在网络层分片和组装的过程中，上层（传输和应用）并不知晓。
		丢包是有概率的。分片就是增加了丢包的概率。
		一旦丢包影响的是上层传输层，那么需要进行重发操作了。

	但是网络层说了不算，彻底解决分片问题，要在传输层进行控制！
		
--------IP---
以公网IP为切入点	IPV4 - 32位 2^32次方（主流IP地址）
	前几位代表某个国家。每个国家的IP地址，在开始的时候已经被划分好了，国际上的路由器都有自己的路由表，可以进行国家和国家的转发。
	然后后面再对于国家，逐步细分。 - 也就是说存在规律。
	当然，也不一定严格要求，针对地区不同需要进行评估进行划分IP地址。
	划分IP地址 - 是运营商决定。

	需要对IP进行划分，才会有网络划分的问题、

-----网段划分（重要）
	IP地址分为两个部分：网络号 （会不断变化，保证连接两个网段不同的标识，）和主机号（同一网段里，相同网络号，不同的主机号）
	IP = 网络 + 主机。
	为什么？类比：学号。对于个人来说：21080502 - 网络号，10 - 主机号
		-网络号可以再不同的查找过程中，是不断变大，并且收敛的。
		-网络距离变长：1.可靠性2.定位目标主机！
	
	公网 - 国际上好比：国家与国家、国家里：省与省。.....
	为了：1.便于定位 2.提高查找的效率。


-具体的网段划分
	子网实际上就是网络号相同 里面主机号不同
	手动管理子网里的IP会非常麻烦。
		-动态分配子网里的ip。
		路由器自动分配和回收子网内新增的节点技术 - DHCP，不用手动进行管理。
		路由器也可以看成DHCP服务器。

	

	过去提出了一种策略：分类划分法。
	-但是随着互联网发展，此缺点会导致大量的IP地址浪费掉。
	
	-子网掩码来区分网络号和主机号。
	1111 1111 0000 0000 1110 0001 0001 0001 IP
	1111 1111 1111 1111 1111 1111 1111 0000 子网掩码 & -（可以给不同路由器配置不同位数的子网掩码）
---------------------------------------------------------------------------
	1111 1111 0000 0000 1110 0001 0001 0000 -网络号
	
	目的IP & 当前路由器的子网掩码 = 该报文需要去的目的网络 -> 因为不同的路由器一定要级联2个网络。每一个网络的网络号可能是不同的。每个路由器都要给自己直接连接的网络
	/24 表示前24位为网络号
	
	特殊的IP地址：
	1.主机地址全为0，称为网络号，代表整个局域网。
	2.全1广播地址，给同一个链路中相互连接的所有主机发送数据包。
	3.127*环回。

	IP地址的数量限制；
		大概43亿左右，实际上：IP地址按照网卡-配置一个。
		CIDR一定程度上缓解了（提高了利用率）但是上限并没有增加
			动态分配IP
			NAT技术
			IPV6
	IP不足怎么办？

-私有IP和公有IP（私有IP、公网IP）
	
	1.你家里要上网，你家先会做什么？
		a、有运营商，在你家附近有网络覆盖
		b、家人联系运营商进行光纤入户
		c、工作人员上门，调制解调器（猫），无线路由器。
		d、开户、账号、密码，配置路由器(账号，密码 -- 运营商认证你们的密码)；
		e、配置路由器 -- 设置路由器的wifi名称+密码（路由器认证人的）
		f、正常上网，按月或者按年缴费。

	2.我们玩bilibili...... 到了月底，充话费却给了运营商？为什么？
		基础设施是运营商铺设的。
		访问任何网页资源，首先都是经过运营商的。		

	3.初步理解一下：我们访问不了谷歌、等国外网站的，为什么？
		运营商。
		无论是你的手机，还是家里的路由器都有账号。
			-认证：余额是否够，够放行，不够，丢弃！
			也可以将对应账号设置欠费等，欠费拦截。
			合法性、账号等识别。
		对于墙来说，直接报文丢弃即可。

	路由器天然会构建局域网（子网）
	数据包没有发送到公网时，用的都是私有IP。
		私有网络对于的IP时局部的。可以在不同的子网中出现重复的。--IP不足问题就大大缓解了。

	家用路由器：
		1.对内：面对自己构建的子网
		2.对外，自己本身也是别人构建子网的一个主机。
	-路由器两套地址：1.对内：Lan口IP，局域网IP、2.对外：WAN口IP，自己所在上级子网给自己分配的IP
	
	src：192.168.1.201, dst: 122.77.241.3
		目的是明确的，是一个公有IP。那么，怎么回来? src:122.77.241.3 dst:192.168.1.201？此时dst不具备唯一性。

	所以在传递过程中：src：192.168.1.201, dst: 122.77.241.3 -家用路由器->WAN口IP   ->......
	1.将报文中的源IP替换为路由器的WAN口IP。
	2.每经过一个运行商的内网路由器，都要做这个工作（公网的内网不做）
	-源IP地址在不同内网、不同层级的网络节点中转发，被替换的技术：NAT技术。
		然后还有几步，之后说。

	对于子网来说，-可以在里面推行IPV6即可。--公网使用IPV4.   当有一天，在局域网中使用增多，IPV6会占据大优势。


----路由过程
	一跳一跳的过程。
	IP数据包传输过程和问路一样。
		路由器查看数据包目的IP，决定是否直接发送给目标主机，还是需要发送给下一个路由器（公网转发），如果不知道发送给默认路由器（内网转发）。
		一直反复，直到目标IP地址。
		先找目标网络，然后在找目标主机。
	
	每个设备都会维护一个路由表
	路由表具体是什么样子？route

路由表生成算法 - 图论算法。



TCP/IP：可靠的将数据从A主机送到B主机。
	跨网络输送。
	1.目的IP
	2.子网划分
	3.路由查找和路由算法。
	--IP没有解决设备转发的具体功能，IP提供的是转发的策略！



---------------------数据链路层--------------
	网络层逻辑上解决了一个主机到另外一个主机。但是实际解决数据传输，一个一个跳的就是数据链路层。
	
	决定将数据交付給下一跳路由器的时候，下一跳路由器一定和我在同一个局域网。-子网。
	每一个节点本质就是子网转发。->宏观上，所有的网络由一个个子网构成的。
	

	数据链路层 - 属于驱动程序的一部分。
	局域网标准指定的很多不一样。代表性的就是以太网、无线LAN等
	
	光纤 - 猫 - >无线路由器
	（数字信号和模拟信号进行转换）
	以太网网线必须使用双绞线。


1.看链路层的数据帧格式（传输层：数据段，网络层：数据包）
	网卡出场时已经内嵌了，标识主机唯一性的方案。MAC地址：48位整数
	以太网帧：封装：
	目的地址 源地址 类型 IP报文 CRC4位（校验和） 6 6 2 数据 4  直接分离即可
		         0800类型 IP数据报    -交给上层谁
		         0806类型 ARP请求/应答 PAD
		         8035类型 RARP 请求/应答 PAD	
	
	
	
2.重谈局域网通信原理
	H1 	H2	H3
	--------------------------  路由器 ----------------------
	H4	H5	H6

H1 - > H6 (MAC: m1->m6  IP: i1->i6)
	m6 m1 0800 数据 CRC    -- 当前局域网内所有主机都收到了
	H分别将目的地址和自己对比，不是直接丢弃，H6收到了，分析后，确认是自己的，报头和有效载荷分离，然后向上转发。
	
	局域网中如何保证我在发送消息的时候，别人也能发送消息呢？-无法控制别人。如果局域网中同时有多台主机都在发送信息，此时就会发生碰撞问题。
	此时发送碰撞问题，我自己是能够感受到的。比如在教室内的混乱。-此时数据就无法使用了。尽量不发生碰撞问题。碰撞避免算法，发送主机会休息随机时间，然后重新发送！
	

	此时这个局域网 --- 就是共享资源 - 此时传输数据 - 就是进程间通信。此时不可被干扰或 --此时就是临界资源。

	问题：1.局域网中主机越多越好，还是越少越少？越少 如果非得要很多的话，可以增加一种设备：交换机switch，划分碰撞域，在区域上减少碰撞概率。
		
	2.局域网数据帧发送的时候，数据帧越长越好还是越短越好？数据帧有最小大小的规定，最大字节数的规定。（以太网：46、1500byte）MTU

	-局域网攻击原理。
	一直发信息。（自己也有碰撞避免算法）-可以借助工具，绕开链路层，直接发网卡。

3.汇总到总体通信流程中。	
	a、在网络转发的过程中，目的IP是不变的，mac帧报头会变化的。
h1			R1					h2
			路由器：	
			网络层	
[R1][h1][0800]有效数据[CRC]	数据链路层	[h2][R1][0800]有效数据[CRC]
			物理层
	
	
	那么，我们这里如何知道对方的MAC地址呢？在同一局域网找到对方的MAC地址。数据帧


补充内容：
MTU：（最大1500byte）IP报头 + TCP报头 + DATA（MSS）
		20标准大小    20标准大小
MSS不要超过 1460.超过的话就需要网络层分片了。
	TCP在建立连接的时候，双方会进行MSS协商。
	发送SYN的时候会在选项中设置好自己支持的MSS。

--------------------------------
ARP协议

路由器a		b		c		d

——————————————————————————————————

e		f		g		h


目标IP: ip = 目标网络 + 目标主机 - > 必须知道MAC地址。没有MAC地址就无法发送

-在同一个网段，需要通过目标IP，得到对方的MAC地址 -- ARP协议，地址解析协议。
----局域网协议！----------

和以太网协议的关系：
......
网络层
数据链路层：
	ARP协议 - 局域网协议
	以太网协议，MAC


-ARP的工作过程：
	现在只看bcfg主机。
	当前b->g 现在，b已知g的IP_G 不清楚对方的MAC。b自己的IP_B, 自己的MAC：MAC_B


	ARP的协议格式：
		（局域网具有广播的效果）
		举例：教师只知道学生的姓名，不知道其学号，现在向全班学生问指定学生的学号。-ARP
		
			1，先广播 2. 一对一发送，MAC在局域网中完成。



			  （0800  IP->MAC ）
		-28byte-       转化什么样的地址
		1硬件类型(2) 协议类型(2) 硬件地址长度(1) 协议地址长度(1)	--固定格式
		局域网的网络类型		6	4
		（1-以太网）
		
		
		2OP字段：
				结论：1.任何主机可能之前向目标主机发起过ARP请求，也会收到对应的ARP应答。
	         			          2.任何一台主机，也可能被别人发起ARP请求。
				局域网中任何一台主机收到ARP的时候，可能是一个应答，也可能时一个请求。
				需要区分。使用OP字段即可。


 		3发送端的MAC地址(6) 发送端IP地址(4) 目的以太网地址(6)目标主机IP(4)
						FF... 111(表示未知)



	b->g的MAC地址。
		b的ARP报头格式：
		1 0800 6 4 1 MAC_B IP_B FF.... IP_G	->ARP层构建好了， 前面加上MAC帧的报头，此时有效数据变成了ARP的报文		1表示请求 op字段

		MAC帧的报头：FF...  MAC_B 0806(目标地址未知，广播， 0806 ARP协议)
		
		广播，此时所有的主机都收到了请求。
		对于广播来说，都要在数据链路层，将其交付给ARP层。交付给后，首先看op字段：先区分时请求还是应答。1就是一个请求，然后找目的IP地址对比，对比不成功抛弃，成功就保留。
		此时g主机开始构建应答ARP字段。
		1 0800 6 4 2 MAC_G(想要得到的目标信息) IP_G MAC_B IP_B
			2表示ARP应答		        (此时都是知道的)
		
		然后向下交付添加MAC帧报头。MAC_B  MAC_G 0806 + ARP报文
			注意此时MAC_B 并不冲突，因为时分给两层看的，并且都会解包。
		


		注意：两次丢弃的场景不一样：1.丢弃在ARP层丢的，2.在底层MAC层丢的。（第一次由于时广播，所以需要解包一层向上传递一层）
		
		主机B收到应答后，可能应答可能请求，首先判断op字段。识别到2后意识到应答，此时提取对方的主机的MAC_G地址，接下来就可以将历史的报文封装向下交付。
				
	
	总结：ARP前提需要知道目标的IP，只有根据此得到对方的MAC地址。
	arp至少要进行一个请求和一个应答，是不是每一次发送数据都要这么干呢？
		并不需要。arp请求成功之后，请求方会暂时将IP和MAC地址的映射关系保存下来。（存在一定时间，比如15min.... ）-为什么不一直保存呢？因为主机断开重新连接后，会重新分配IP地址。
	并且arp的过程会在网络传输的任意路径里。-并且IP分片也有可能会进行分片。（概率比较小）
	
	实验：arp -a 查看此服务器上的mac - ip，比如想获取：ifconfig：首先得到网络号。while 遍历[1, 254] ping -c1 172.28.71.number; number++; done;
	向所有主机发送包。ping获得缓存即可。
	
	ping 目标主机ip （windows默认几次）

-如何通过arp攻击成为中间人，arp欺骗。

	主机A		——		routeB
			局域网
		
	假设：			
	192.168.1.1			192.168.1.3
	mac_b				mac_a
			主机C
		疯狂向B构建发送大量ARP应答-我是主机A，mac_c, ipa。->
		注意，取新不取旧，会更新arp缓存，将立马的mac_a修改为mac_c
		<-疯狂向A构建发送大量ARP应答-我是路由器B，mac_c, ipb。
		会更新arp缓存，将立马的mac_b修改为mac_c

		之后，将首先发送给主机C，然后就可以转给路由器B。


	此arp欺骗就可以让指定主机进行掉线.



-------------------------------------------------------------------------------------------------------------------------
应用层 -如何处理
传输层 -可靠性
网络层 -路由
数据链路层

其他重要的协议或技术。NAT - 推送出去可以 -

DNS 应用层协议。
域名转化为ip
	让用户用起来舒服。

	域名解析服务。-呈现一种区域性。
	浏览器进行DNS域名解析服务 - > udp协议返回一个ip。（向上访问到根域名解析服务器）浏览器会缓存。
		域名解析服务器 -- 根域名服务器-> 美国
	
	有的时候，qq、游戏时正常登录的，但是网页打不开。在用DNS，浏览器内置的DNS ip地址服务挂掉了。
	

-面试题：

	浏览器输入url，得到网页页面得流程。
	-协议栈均涉及到了。
	1.回答整体结构，重点放在应用层：http、https、部分涉及到tcp。
	2.和面试官沟通是否进一步讨论细节，针对细节进行讨论，给别人进行表述。

	

NAT技术
	解决当前IP地址的主要手段。
	出去：将源IP替换位公网中存在的路由器。（实际上公网上应该是运营商的路由器，在传达这一过程中路由器也是转化为上一层子网IP即可）然后就是正常的路由转发。
	接收的时候：将目标地址根据之前的：目标地址映射的私网ip，替换即可，然后发送给指定的主机即可。
	

	NAPT - 映射表：
	维护的是：
	私网	公网
	源IP	源IP   （NAT转化）
	目的IP	目的IP（不变）
	-四元组

	1.其实在进行源地址转化的过程中，可能不一定只替换原IP，必要的时候，源端口也要替换！（当存在内网端口号相同的时候，转化外网端口的时候路由器会对于进行处理）
	2.路由器在NAT转化的过程中，除了单纯的替换，还会为我门根据报文请求的四元组，为我们构建一个映射关系。
	3.源IP表示唯一的一台主机，源端口表示该主机上唯一的进程，源IP+源端口 - 表示唯一的一个进程。（对于内外网来说）
	4.无论从内向外，都能表示各自网络中表示唯一性，所以，这个映射关系：互为key值的！
	5.如果从来没有访问过外网，外网能够直接访问内网吗？-理论上是不能的，因为无法进行NAT转化。
	6.但是存在很多基于NAT原理的软件，能够帮助我们从外网访问内网 -- 内网穿透。


NAT的限制：
	外部无法向内部服务器建立链接；（可以想办法）
	转化表的生存和消耗存在额外开销
	NAT设备一旦异常，即使存在热备（存在一个的备份，外网发送到另外一个），所有TCP连接也都会断开；
	
	

NAT和代理服务器：
-代理服务器：
	比如学校的代理服务器。
	1.身份认证。
	2.缓存数据，提高访问效率。
	3.内容审核。
	4.保证内网安全。
	
	--正向代理服务器。一般由web服务器来承担，Nginx。（替你做事情的就是正向代理）

	公司设立服务建立机房的时候会维护一个代理服务器。
	客户端访问公司资源的时候，请求首先转发到此代理服务器上，会将所有的请求通过一定的方式比如轮询、随机数等方式。比如建立一个IP与访问压力cnt的映射关系。不做任何业务的处理，只负责将请求推送到后端的指定主机。保证整个集群的负载均衡。
	--反向服务器。

	并且可以随机返回域名解析结果，-这样可以将同一个域名解析到不同的IP上，可以做到不同服务器的负载均衡。
	一般，反向服务器前会增加一个防火墙。-检测是否恶意，存在恶意直接拦住。

	从应用上将：NAT严格上讲是存在网络层的。（但是是做了特殊处理，会得到一个端口），目标是解决IP不足的功能。
	但是代理服务器：-比如翻墙和加速器。访问某种资源的时候，不去大家公用访问的设备，而是就近或者缓存资源达到加速的功能。并且是处于应用层。
	翻墙：广域网中的代理。

--------------------------------------------------------------------
访问外网 - fq
	国内
	客户端		运营商				公网		外部世界
			我们所有的请求，都必须经过运营商
			（检查数据，ip是国内可以直接访问的）
					
			xg地区
			这些机器是能够直接被大陆地区访问，并且也能直接访问外网的。
			<->
				（搭建一个代理服务器）
	http			1.1.1.1					www.g.com
	请求->1.1.1.1	
	对外网http有效载荷做加密	此时读取加密有效载荷，
	-数据是一个http请求。	解密，转发出外网。->
	(先传给运营商)
	(运营商发送给你)
	解密<-			加密，添加相应http				响应报文
				http/1.1 ......				<-
				
----------------------------------------------------
网络基础总结：

数据链路层

网络层
	数据转发，定位目标主机
传输层
	保证可靠性。
应用层
	解析数据（......序列化和反序列化，解决粘包..），数据分析。
